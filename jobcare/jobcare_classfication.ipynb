{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jobcare_classfication.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tmHlyK1mqg6",
        "outputId": "fdc06bdc-5db2-426c-ddc8-52f77b223a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google import colab\n",
        "colab.drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/data/jobcare/\"\n",
        "SUBMIT_PATH = \"/content/drive/MyDrive/data/jobcare/submit/\"\n",
        "SEED = 0"
      ],
      "metadata": {
        "id": "o8k1o8uEn3wV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg55cASdoWT2",
        "outputId": "1cf21e47-effb-4c37-9cd1-f77fa728b715"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.0.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=3ea6be5687eae9b9747a1aaa89eb3339388020f4dd343d251d7f9ae8dfab852d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import platform\n",
        "import random\n",
        "import math\n",
        "from typing import List ,Dict, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "import sklearn \n",
        "from sklearn.model_selection import StratifiedKFold , KFold\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "from catboost import Pool,CatBoostClassifier\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "metadata": {
        "id": "AtAU18OGoWlo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(f'{DATA_PATH}train.csv')\n",
        "test_data = pd.read_csv(f'{DATA_PATH}test.csv')\n",
        "\n",
        "code_d = pd.read_csv(f'{DATA_PATH}속성_D_코드.csv')\n",
        "code_h = pd.read_csv(f'{DATA_PATH}속성_H_코드.csv')\n",
        "code_l = pd.read_csv(f'{DATA_PATH}속성_L_코드.csv')"
      ],
      "metadata": {
        "id": "VQy-zBtYoc2p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_d.columns= [\"attribute_d\",\"attribute_d_d\",\"attribute_d_s\",\"attribute_d_m\",\"attribute_d_l\"]\n",
        "code_h.columns= [\"attribute_h\",\"attribute_h_m\", \"attribute_h_l\"]\n",
        "code_l.columns= [\"attribute_l\",\"attribute_l_d\",\"attribute_l_s\",\"attribute_l_m\",\"attribute_l_l\"]"
      ],
      "metadata": {
        "id": "cmLD8TlaodOw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_codes(df:pd.DataFrame,df_code:pd.DataFrame,col:str)->pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df_code = df_code.copy()\n",
        "    df_code = df_code.add_prefix(f\"{col}_\")\n",
        "    df_code.columns.values[0] = col\n",
        "    return pd.merge(df,df_code,how=\"left\",on=col)\n",
        "\n",
        "def preprocess_data(\n",
        "                    df:pd.DataFrame,is_train:bool = True, cols_merge:List[Tuple[str,pd.DataFrame]] = []  , cols_equi:List[Tuple[str,str]]= [] ,\n",
        "                    cols_drop:List[str] = [\"id\",\"person_prefer_f\",\"person_prefer_g\" ,\"contents_open_dt\"]\n",
        "                    )->Tuple[pd.DataFrame,np.ndarray]:\n",
        "    df = df.copy()\n",
        "\n",
        "    y_data = None\n",
        "    if is_train:\n",
        "        y_data = df[\"target\"].to_numpy()\n",
        "        df = df.drop(columns=\"target\")\n",
        "\n",
        "    for col, df_code in cols_merge:\n",
        "        df = merge_codes(df,df_code,col)\n",
        "\n",
        "    cols = df.select_dtypes(bool).columns.tolist()\n",
        "    df[cols] = df[cols].astype(int)\n",
        "\n",
        "    for col1, col2 in cols_equi:\n",
        "        df[f\"{col1}_{col2}\"] = (df[col1] == df[col2] ).astype(int)\n",
        "\n",
        "    df = df.drop(columns=cols_drop)\n",
        "    return (df , y_data)"
      ],
      "metadata": {
        "id": "T6dlbqGdo5A8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_merge = [\n",
        "              (\"person_prefer_d_1\" , code_d),\n",
        "              (\"person_prefer_d_2\" , code_d),\n",
        "              (\"person_prefer_d_3\" , code_d),\n",
        "              (\"contents_attribute_d\" , code_d),\n",
        "              (\"person_prefer_h_1\" , code_h),\n",
        "              (\"person_prefer_h_2\" , code_h),\n",
        "              (\"person_prefer_h_3\" , code_h),\n",
        "              (\"contents_attribute_h\" , code_h),\n",
        "              (\"contents_attribute_l\" , code_l),\n",
        "]\n",
        "\n",
        "# 회원 속성과 콘텐츠 속성의 동일한 코드 여부에 대한 컬럼명 리스트\n",
        "cols_equi = [\n",
        "\n",
        "    (\"contents_attribute_c\",\"person_prefer_c\"),\n",
        "    (\"contents_attribute_e\",\"person_prefer_e\"),\n",
        "\n",
        "    (\"person_prefer_d_2_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n",
        "    (\"person_prefer_d_2_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n",
        "    (\"person_prefer_d_2_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n",
        "    (\"person_prefer_d_3_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n",
        "    (\"person_prefer_d_3_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n",
        "    (\"person_prefer_d_3_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n",
        "\n",
        "    (\"person_prefer_h_1_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
        "    (\"person_prefer_h_2_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
        "    (\"person_prefer_h_3_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
        "    (\"person_prefer_h_1_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
        "    (\"person_prefer_h_2_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
        "    (\"person_prefer_h_3_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
        "\n",
        "]\n",
        "\n",
        "# 학습에 필요없는 컬럼 리스트\n",
        "cols_drop = [\"id\",\"person_prefer_f\",\"person_prefer_g\" ,\"contents_open_dt\", \"contents_rn\", ]"
      ],
      "metadata": {
        "id": "xt9IFi3QqOVo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = preprocess_data(train_data, cols_merge = cols_merge , cols_equi= cols_equi , cols_drop = cols_drop)\n",
        "x_test, _ = preprocess_data(test_data,is_train = False, cols_merge = cols_merge , cols_equi= cols_equi  , cols_drop = cols_drop)\n",
        "x_train.shape , y_train.shape , x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmARDnxPqq14",
        "outputId": "9b03ebd8-216d-4e9a-9c13-b7dcf8c21b0c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((501951, 71), (501951,), (46404, 71))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = x_train.columns[x_train.nunique() > 2].tolist()"
      ],
      "metadata": {
        "id": "9LmLbNqmqs8f"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_holdout = False\n",
        "n_splits = 5\n",
        "iterations = 3000\n",
        "patience = 50\n",
        "\n",
        "pbounds = {\"depth\": (2,7),\n",
        "           \"learning_rate\": (.01, 0.2),\n",
        "           \"subsample\":(0.6, 1.),\n",
        "           \"num_leaves\": (16,40),\n",
        "           \"max_bin\":(150,300),\n",
        "           \"l2_leaf_reg\":(0,10),\n",
        "           \"model_size_reg\": (0,10)\n",
        "}\n",
        "\n",
        "scores = []\n",
        "models = []"
      ],
      "metadata": {
        "id": "VXSsTp8OqvYW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CB_opt(depth, learning_rate, max_bin,\n",
        "             subsample, num_leaves, l2_leaf_reg, model_size_reg):\n",
        "  cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "  scores = []\n",
        "  models = []\n",
        "  for tri, vai in cv.split(x_train, y_train):\n",
        "      # print(\"=\"*50)\n",
        "      preds = []\n",
        "\n",
        "      model = CatBoostClassifier(iterations=iterations,random_state=SEED,task_type=\"GPU\",eval_metric=\"F1\",\n",
        "                                learning_rate=learning_rate, cat_features=cat_features,one_hot_max_size=4,\n",
        "                                use_best_model = True,grow_policy = \"Lossguide\",\n",
        "                                 subsample = subsample, \n",
        "                                 max_bin = int(max_bin),  \n",
        "                                 model_size_reg = model_size_reg,\n",
        "                                 max_depth = int(depth),\n",
        "                                 num_leaves = int(num_leaves),\n",
        "                                 l2_leaf_reg = l2_leaf_reg,\n",
        "                                 verbose = 0,\n",
        "                                 bootstrap_type='Poisson'\n",
        "      )\n",
        "\n",
        "      model.fit(x_train.iloc[tri], y_train[tri], \n",
        "              eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
        "              early_stopping_rounds=patience ,\n",
        "          )\n",
        "      \n",
        "      models.append(model)\n",
        "      scores.append(model.get_best_score()[\"validation\"][\"F1\"])\n",
        "      if is_holdout:\n",
        "          break\n",
        "\n",
        "  return np.mean(scores)"
      ],
      "metadata": {
        "id": "GBQgtQEh5itW"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = BayesianOptimization(\n",
        "    f = CB_opt,\n",
        "    pbounds = pbounds,\n",
        "    verbose = 2,\n",
        "    random_state = 888,\n",
        ")\n",
        "\n",
        "optimizer.maximize(init_points = 2, n_iter = 20)\n",
        "\n",
        "print(optimizer.max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLRuEQCC63ev",
        "outputId": "4f624104-8f13-4a50-dcd2-73018c6916e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |   depth   | l2_lea... | learni... |  max_bin  | model_... | num_le... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores)\n",
        "print(np.mean(scores))"
      ],
      "metadata": {
        "id": "c11laEsVqyyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.4\n",
        "pred_list = []\n",
        "scores = []\n",
        "for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
        "    pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
        "    pred = np.where(pred >= threshold , 1, 0)\n",
        "    score = f1_score(y_train[vai],pred)\n",
        "    scores.append(score)\n",
        "    pred = models[i].predict_proba(x_test)[:, 1]\n",
        "    pred_list.append(pred)\n",
        "print(scores)\n",
        "print(np.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TCz-CJHq8rA",
        "outputId": "51481f98-c4ef-4d25-b9ad-9532f724612d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7092373652072237, 0.7101217759867708, 0.7113621707223495, 0.7101059316898165, 0.7113003846526813]\n",
            "0.7104255256517684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.mean( pred_list , axis = 0 )\n",
        "pred = np.where(pred >= threshold , 1, 0)"
      ],
      "metadata": {
        "id": "QL-5nXqtrBcB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
        "sample_submission['target'] = pred"
      ],
      "metadata": {
        "id": "nZfKOKmZrEFw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.to_csv(f\"{SUBMIT_PATH}prediction.csv\", index=False)"
      ],
      "metadata": {
        "id": "IYsCsOdwtWwt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jMlZI7NJtv6J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}