{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17866,
     "status": "ok",
     "timestamp": 1605356696661,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "T5GN2My_oCC5",
    "outputId": "61a53871-b4cd-4199-bdea-b32fe82bed08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd drive/My Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토론글에 있는 pytorch 이용한 코드 사용\n",
    "- model을 10개로 늘리고 epoch을 30정도, model을 더 복잡하게 해서 0.782 정도 나왔음.\n",
    "\n",
    "\n",
    "## 추가 process\n",
    "- test의 각 model의 예측값 가져와서 모든  model이 동일하게 예측한 test data를 train에 넣어 재구성하는 전략 사용 \n",
    "    - 맞춘 비율이 어느 정도 되기 때문에 약간의 효율이 있을 것 같아서 적용해 봄.\n",
    "- 재학습시킨 후 0.784정도\n",
    "\n",
    "<br>\n",
    "\n",
    "- 그 외 시도했으나 비슷하거나 큰 효과가 없던 방법\n",
    "    - 마키아벨리즘 score나 time을 scale변환 후 적용.\n",
    "    - test에서 동일한 예측값이 아닌 prediction에서 1.25이하 1.75이상 나온 test data를 train에 추가\n",
    "    - train data에서 오분류된 데이터를 가지고 추가 학습을 하는 방식 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3311,
     "status": "ok",
     "timestamp": 1605356701921,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "R2aS2V8WoMpH"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "train_data = pd.read_csv('data/open data/train.csv',index_col='index').drop([379, 24598], axis=0)\n",
    "test_data = pd.read_csv('data/open data/test_x.csv',index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 1360,
     "status": "ok",
     "timestamp": 1605255161678,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "XIbH0GJhpjju",
    "outputId": "555f0bef-9615-477b-ead6-cfa2cbb3389b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>QeE</th>\n",
       "      <th>QfA</th>\n",
       "      <th>QfE</th>\n",
       "      <th>QgA</th>\n",
       "      <th>QgE</th>\n",
       "      <th>QhA</th>\n",
       "      <th>QhE</th>\n",
       "      <th>QiA</th>\n",
       "      <th>QiE</th>\n",
       "      <th>QjA</th>\n",
       "      <th>QjE</th>\n",
       "      <th>QkA</th>\n",
       "      <th>QkE</th>\n",
       "      <th>QlA</th>\n",
       "      <th>QlE</th>\n",
       "      <th>QmA</th>\n",
       "      <th>QmE</th>\n",
       "      <th>QnA</th>\n",
       "      <th>QnE</th>\n",
       "      <th>QoA</th>\n",
       "      <th>QoE</th>\n",
       "      <th>QpA</th>\n",
       "      <th>QpE</th>\n",
       "      <th>QqA</th>\n",
       "      <th>QqE</th>\n",
       "      <th>QrA</th>\n",
       "      <th>QrE</th>\n",
       "      <th>QsA</th>\n",
       "      <th>QsE</th>\n",
       "      <th>QtA</th>\n",
       "      <th>QtE</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>engnat</th>\n",
       "      <th>familysize</th>\n",
       "      <th>gender</th>\n",
       "      <th>hand</th>\n",
       "      <th>married</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>tp01</th>\n",
       "      <th>tp02</th>\n",
       "      <th>tp03</th>\n",
       "      <th>tp04</th>\n",
       "      <th>tp05</th>\n",
       "      <th>tp06</th>\n",
       "      <th>tp07</th>\n",
       "      <th>tp08</th>\n",
       "      <th>tp09</th>\n",
       "      <th>tp10</th>\n",
       "      <th>urban</th>\n",
       "      <th>voted</th>\n",
       "      <th>wf_01</th>\n",
       "      <th>wf_02</th>\n",
       "      <th>wf_03</th>\n",
       "      <th>wr_01</th>\n",
       "      <th>wr_02</th>\n",
       "      <th>wr_03</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>363</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1370</td>\n",
       "      <td>5.0</td>\n",
       "      <td>997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1577</td>\n",
       "      <td>5.0</td>\n",
       "      <td>539</td>\n",
       "      <td>2.0</td>\n",
       "      <td>586</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1142</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1287</td>\n",
       "      <td>4.0</td>\n",
       "      <td>883</td>\n",
       "      <td>4.0</td>\n",
       "      <td>851</td>\n",
       "      <td>2.0</td>\n",
       "      <td>851</td>\n",
       "      <td>5.0</td>\n",
       "      <td>816</td>\n",
       "      <td>2.0</td>\n",
       "      <td>579</td>\n",
       "      <td>2.0</td>\n",
       "      <td>924</td>\n",
       "      <td>2.0</td>\n",
       "      <td>366</td>\n",
       "      <td>2.0</td>\n",
       "      <td>876</td>\n",
       "      <td>2.0</td>\n",
       "      <td>633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>30s</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1313</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4320</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4082</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1867</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1264</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2943</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4329</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1214</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2414</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1346</td>\n",
       "      <td>20s</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Hindu</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>531</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1016</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2653</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1569</td>\n",
       "      <td>5.0</td>\n",
       "      <td>998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2547</td>\n",
       "      <td>2.0</td>\n",
       "      <td>918</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2153</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>937</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1409</td>\n",
       "      <td>30s</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>357</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1519</td>\n",
       "      <td>4.0</td>\n",
       "      <td>159</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2809</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5614</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3219</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9046</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1216</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1169</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23868</td>\n",
       "      <td>3.0</td>\n",
       "      <td>581</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8830</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2392</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1312</td>\n",
       "      <td>20s</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Hindu</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>707</td>\n",
       "      <td>5.0</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>2.0</td>\n",
       "      <td>628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1153</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1388</td>\n",
       "      <td>5.0</td>\n",
       "      <td>740</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1181</td>\n",
       "      <td>4.0</td>\n",
       "      <td>547</td>\n",
       "      <td>2.0</td>\n",
       "      <td>575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>754</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1140</td>\n",
       "      <td>5.0</td>\n",
       "      <td>323</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1889</td>\n",
       "      <td>20s</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>White</td>\n",
       "      <td>Agnostic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QaA   QaE  QbA   QbE  QcA  ...  wr_09  wr_10  wr_11  wr_12  wr_13\n",
       "index                             ...                                   \n",
       "0      3.0   363  4.0  1370  5.0  ...      0      1      0      1      1\n",
       "1      5.0   647  5.0  1313  3.0  ...      0      1      0      1      1\n",
       "2      4.0  1623  1.0  1480  1.0  ...      1      1      0      1      1\n",
       "3      3.0   504  3.0  2311  4.0  ...      0      1      0      1      1\n",
       "4      1.0   927  1.0   707  5.0  ...      0      1      1      1      1\n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 994888,
     "status": "ok",
     "timestamp": 1605364985983,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "yz7kCueUq0Y1",
    "outputId": "efd4784b-7092-452e-81d2-4de1f570a11c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10: 100%|██████████| 40/40 [01:38<00:00,  2.47s/it]\n",
      "02/10: 100%|██████████| 40/40 [01:38<00:00,  2.46s/it]\n",
      "03/10: 100%|██████████| 40/40 [01:38<00:00,  2.46s/it]\n",
      "04/10: 100%|██████████| 40/40 [01:39<00:00,  2.48s/it]\n",
      "05/10: 100%|██████████| 40/40 [01:37<00:00,  2.43s/it]\n",
      "06/10: 100%|██████████| 40/40 [01:37<00:00,  2.45s/it]\n",
      "07/10: 100%|██████████| 40/40 [01:38<00:00,  2.46s/it]\n",
      "08/10: 100%|██████████| 40/40 [01:38<00:00,  2.47s/it]\n",
      "09/10: 100%|██████████| 40/40 [01:39<00:00,  2.49s/it]\n",
      "10/10: 100%|██████████| 40/40 [01:39<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_data = pd.read_csv('data/open data/train.csv').drop([379, 24598], axis=0)\n",
    "test_data = pd.read_csv('data/open data/test_x.csv')\n",
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "             'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "             'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "             'index', 'hand']\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}\n",
    "train_y = train_data['voted']\n",
    "train_x = train_data.drop(drop_list + ['voted'], axis=1)\n",
    "test_x = test_data.drop(drop_list, axis=1)\n",
    "train_x = train_x.astype(replace_dict)\n",
    "test_x = test_x.astype(replace_dict)\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)\n",
    "train_y = 2 - train_y.to_numpy()\n",
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "\n",
    "train_x[:, :20] = (train_x[:, :20] - 3.) / 2.\n",
    "test_x[:, :20] = (test_x[:, :20] - 3.) / 2\n",
    "train_x[:, 20] = (train_x[:, 20] - 5.) / 5.\n",
    "test_x[:, 20] = (test_x[:, 20] - 5.) / 5.\n",
    "train_x[:, 21:31] = (train_x[:, 21:31] - 3.5) / 3.5\n",
    "test_x[:, 21:31] = (test_x[:, 21:31] - 3.5) / 3.5\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "train_len, test_len = len(train_x), len(test_x)\n",
    "\n",
    "N_MODEL = 10\n",
    "N_EPOCH = 30\n",
    "BATCH_SIZE = 128\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True\n",
    "}\n",
    "prediction = np.zeros((11383, 1), dtype=np.float32)\n",
    "predict = np.zeros((11383, 10), dtype=np.float32)\n",
    "\n",
    "for no in range(N_MODEL):\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_x, train_y),\n",
    "                              shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "    test_loader = DataLoader(TensorDataset(test_x, torch.zeros((test_len,), dtype=torch.float32)),\n",
    "                             shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "    model = nn.Sequential(\n",
    "        nn.Dropout(0.05),\n",
    "        nn.Linear(91, 104, bias=False),\n",
    "        nn.BatchNorm1d(104),\n",
    "        nn.LeakyReLU(0.05, inplace=True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(104, 80, bias=False),\n",
    "        nn.BatchNorm1d(80),\n",
    "        nn.LeakyReLU(0.05, inplace=True),\n",
    "        nn.Linear(80, 64, bias=False),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.LeakyReLU(0.05, inplace=True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(64, 32, bias=False),\n",
    "        nn.BatchNorm1d(32),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(32, 1)\n",
    "    ).to(DEVICE)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=4e-2)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=N_EPOCH // 4, eta_min=1.2e-5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(no + 1, N_MODEL)):\n",
    "        for idx, (xx, yy) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "            pred = model(xx).squeeze()\n",
    "            loss = criterion(pred, yy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch + idx / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (xx, _) in enumerate(test_loader):\n",
    "            xx = xx.to(DEVICE)\n",
    "            pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "            prediction[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] += pred[:, :] / N_MODEL\n",
    "            predict[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)),no] = pred[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1605361423651,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "O_CXNhihu3y7",
    "outputId": "c178fb8e-f993-49eb-8f03-1e195d746bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11383,)"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres = np.round(predict)\n",
    "pres = np.mean(pres,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1605361749279,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "8wLB5sNJ-ar3"
   },
   "outputs": [],
   "source": [
    "train_x1 = torch.cat((train_x, test_x[np.where((pres ==1) | (pres==2))[0],:]), dim=0)\n",
    "test_pre = 2 - pres[np.where((pres ==1) | (pres==2))]\n",
    "test_pre = torch.tensor(test_pre, dtype=torch.float32)\n",
    "train_y1 = torch.cat((train_y, test_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2074,
     "status": "ok",
     "timestamp": 1605360895638,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "TgS1NOIb24eE",
    "outputId": "98a96f95-f298-488f-e48d-35b6b974afb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45440\n"
     ]
    }
   ],
   "source": [
    "train_predict = np.zeros((45440, 1), dtype=np.float32)\n",
    "real = np.zeros((45440, 1), dtype=np.float32)\n",
    "train_loader = DataLoader(TensorDataset(train_x, train_y),\n",
    "                              shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "test_loader = DataLoader(TensorDataset(test_x, torch.zeros((test_len,), dtype=torch.float32)),\n",
    "                             shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (xx, _) in enumerate(train_loader):\n",
    "        xx = xx.to(DEVICE)\n",
    "        pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "        train_predict[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(train_predict)), :] = pred[:, :]\n",
    "        real[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(train_predict)),0] = 2 - _[:]\n",
    "    print(BATCH_SIZE * (idx + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1605360900146,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "7N9Ok6rE4wYz",
    "outputId": "01060c89-bc47-4bb4-94e7-c1e8d264a303"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>17466</td>\n",
       "      <td>3125</td>\n",
       "      <td>20591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>9543</td>\n",
       "      <td>15306</td>\n",
       "      <td>24849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>27009</td>\n",
       "      <td>18431</td>\n",
       "      <td>45440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    1.0    2.0    All\n",
       "True                          \n",
       "1.0        17466   3125  20591\n",
       "2.0         9543  15306  24849\n",
       "All        27009  18431  45440"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.Series(real.flat), pd.Series(np.round(train_predict).flat), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 883744,
     "status": "ok",
     "timestamp": 1605363260297,
     "user": {
      "displayName": "조규영/학생/컴퓨터공학",
      "photoUrl": "",
      "userId": "11564142364387681813"
     },
     "user_tz": -540
    },
    "id": "aytWWSSY7C3b",
    "outputId": "1f0032f0-e376-4cd5-e3bf-46eca9086ad4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10: 100%|██████████| 30/30 [01:26<00:00,  2.88s/it]\n",
      "02/10: 100%|██████████| 30/30 [01:26<00:00,  2.89s/it]\n",
      "03/10: 100%|██████████| 30/30 [01:26<00:00,  2.89s/it]\n",
      "04/10: 100%|██████████| 30/30 [01:27<00:00,  2.93s/it]\n",
      "05/10: 100%|██████████| 30/30 [01:28<00:00,  2.95s/it]\n",
      "06/10: 100%|██████████| 30/30 [01:26<00:00,  2.88s/it]\n",
      "07/10: 100%|██████████| 30/30 [01:27<00:00,  2.92s/it]\n",
      "08/10: 100%|██████████| 30/30 [01:27<00:00,  2.91s/it]\n",
      "09/10: 100%|██████████| 30/30 [01:28<00:00,  2.96s/it]\n",
      "10/10: 100%|██████████| 30/30 [01:31<00:00,  3.07s/it]\n"
     ]
    }
   ],
   "source": [
    "prediction = np.zeros((11383, 1), dtype=np.float32)\n",
    "\n",
    "for no in range(N_MODEL):\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_x1, train_y1),\n",
    "                              shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "    test_loader = DataLoader(TensorDataset(test_x, torch.zeros((test_len,), dtype=torch.float32)),\n",
    "                             shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "    model = nn.Sequential(\n",
    "        nn.Dropout(0.05),\n",
    "        nn.Linear(91, 104, bias=False),\n",
    "        nn.BatchNorm1d(104),\n",
    "        nn.LeakyReLU(0.05, inplace=True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(104, 80, bias=False),\n",
    "        nn.BatchNorm1d(80),\n",
    "        nn.LeakyReLU(0.05, inplace=True),\n",
    "        nn.Linear(80, 64, bias=False),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.LeakyReLU(0.05, inplace=True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(64, 32, bias=False),\n",
    "        nn.BatchNorm1d(32),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(32, 1)\n",
    "    ).to(DEVICE)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=4e-2)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=N_EPOCH // 4, eta_min=1.2e-5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(no + 1, N_MODEL)):\n",
    "        for idx, (xx, yy) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "            pred = model(xx).squeeze()\n",
    "            loss = criterion(pred, yy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch + idx / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (xx, _) in enumerate(test_loader):\n",
    "            xx = xx.to(DEVICE)\n",
    "            pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "            prediction[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] += pred[:, :] / N_MODEL\n",
    "            # predict[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)),no] = pred[:,0]\n",
    "\n",
    "df = pd.read_csv('data/open data/sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction\n",
    "df.to_csv('data/open data/{}1.csv'.format(datetime.now().strftime('%m%d-%H%M')), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BuVlOzoC63k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN9ryEd8yYfptrua499M6dN",
   "collapsed_sections": [],
   "name": "psychometrics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
