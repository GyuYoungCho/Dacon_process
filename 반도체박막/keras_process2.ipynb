{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "train = pd.read_csv('trains.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "for col in train.columns:\n",
    "    col_type = train[col].dtypes\n",
    "    min1 = train[col].min()\n",
    "    max1 = train[col].max()\n",
    "    if str(col_type)[:3] == 'int':\n",
    "        train[col] = train[col].astype(np.int16)\n",
    "    else:\n",
    "        if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n",
    "            train[col] = train[col].astype(np.float16)\n",
    "        elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n",
    "            train[col] = train[col].astype(np.float32)\n",
    "        else:\n",
    "            train[col] = train[col].astype(np.float64)\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train_X = train.iloc[:,4:]\n",
    "train_Y = train.iloc[:,0:4]\n",
    "test_X = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_1</th>\n",
       "      <th>layer_2</th>\n",
       "      <th>layer_3</th>\n",
       "      <th>layer_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>300</td>\n",
       "      <td>280</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer_1  layer_2  layer_3  layer_4\n",
       "0      200       60      200       40\n",
       "1      150      300      280      270\n",
       "2      130       50       30      130\n",
       "3      110       60      110      190\n",
       "4       60       90       60       60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import activations\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=239, activation=mish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.07338))\n",
    "    model.add(Dense(units=252, activation=mish, input_dim=226))\n",
    "    model.add(Dense(units=252, activation=mish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.07338))\n",
    "    model.add(Dense(units=265, activation=mish, input_dim=226))\n",
    "    model.add(Dense(units=265, activation=mish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.07338))\n",
    "    model.add(Dense(units=178, activation=mish, input_dim=226))\n",
    "    model.add(Dense(units=178, activation=mish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.07338))\n",
    "    model.add(Dense(units=91, activation=mish, input_dim=226))\n",
    "    model.add(Dense(units=91, activation=mish, input_dim=226))\n",
    "    model.add(Dense(units=4, activation='linear'))\n",
    "    op = optimizers.Nadam(learning_rate = 0.001014, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model.compile(loss='mae', optimizer=op, metrics=['mae'])\n",
    "    return model\n",
    "def swish(x) :\n",
    "    return x * keras.activations.sigmoid(x)\n",
    "\n",
    "def mish(x) :\n",
    "    return x * keras.activations.tanh( keras.activations.softplus(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 936x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "plt.figure(figsize = (13,8))\n",
    "class LRFinder(Callback):\n",
    "    \n",
    "    def __init__(self, min_lr=1e-5, max_lr=1e-2, steps_per_epoch=None, epochs=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.total_iterations = steps_per_epoch * epochs\n",
    "        self.iteration = 0\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        x = self.iteration / self.total_iterations \n",
    "        return self.min_lr + (self.max_lr-self.min_lr) * x\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.min_lr)\n",
    "        \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.iteration += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.iteration)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "            \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    " \n",
    "    def plot_lr(self):\n",
    "        '''Helper function to quickly inspect the learning rate schedule.'''\n",
    "        plt.plot(self.history['iterations'], self.history['lr'])\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Learning rate')\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        '''Helper function to quickly observe the learning rate experiment results.'''\n",
    "        plt.plot(self.history['lr'], self.history['loss'])\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 1000\n",
    "epoch_size = len(train_X)\n",
    "\n",
    "lr_finder = LRFinder(min_lr=(1e-3), \n",
    "                     max_lr=(1e-3)*5, \n",
    "                     steps_per_epoch=np.ceil(epoch_size/batch_size), \n",
    "                     epochs=epochs)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(patience=5, monitor='val_loss')\n",
    "\n",
    "ckpt_dir = './ckpt1'\n",
    "ckpt_path = ckpt_dir + '/ResNetFinetuning_{epoch:02d}_valloss{val_loss:.2f}.hdf5'\n",
    "ckpt = keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 239)               54253     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 239)               956       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 239)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 252)               60480     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 252)               63756     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 252)               1008      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 252)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 265)               67045     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 265)               70490     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 265)               1060      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 265)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 178)               47348     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 178)               31862     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 178)               712       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 178)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 91)                16289     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 91)                8372      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 368       \n",
      "=================================================================\n",
      "Total params: 423,999\n",
      "Trainable params: 422,131\n",
      "Non-trainable params: 1,868\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model11 = build_model()\n",
    "model11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648000 samples, validate on 162000 samples\n",
      "Epoch 1/100\n",
      "648000/648000 [==============================] - 16s 24us/step - loss: 59.4536 - mae: 59.4536 - val_loss: 51.3733 - val_mae: 51.3733\n",
      "Epoch 2/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 29.8708 - mae: 29.8708 - val_loss: 17.9017 - val_mae: 17.9017\n",
      "Epoch 3/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 15.6355 - mae: 15.6355 - val_loss: 10.3255 - val_mae: 10.3255\n",
      "Epoch 4/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 12.1459 - mae: 12.1459 - val_loss: 8.8741 - val_mae: 8.8741\n",
      "Epoch 5/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 10.4858 - mae: 10.4858 - val_loss: 6.6851 - val_mae: 6.6851\n",
      "Epoch 6/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 9.4925 - mae: 9.4925 - val_loss: 6.8517 - val_mae: 6.8517\n",
      "Epoch 7/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 8.8700 - mae: 8.8700 - val_loss: 5.8211 - val_mae: 5.8211\n",
      "Epoch 8/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 8.4045 - mae: 8.4045 - val_loss: 5.9910 - val_mae: 5.9910\n",
      "Epoch 9/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 8.0483 - mae: 8.0483 - val_loss: 5.5809 - val_mae: 5.5809\n",
      "Epoch 10/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 7.7759 - mae: 7.7759 - val_loss: 5.2934 - val_mae: 5.2934\n",
      "Epoch 11/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 7.5658 - mae: 7.5658 - val_loss: 5.2548 - val_mae: 5.2548\n",
      "Epoch 12/100\n",
      "648000/648000 [==============================] - 14s 21us/step - loss: 7.3506 - mae: 7.3506 - val_loss: 4.9831 - val_mae: 4.9831\n",
      "Epoch 13/100\n",
      "648000/648000 [==============================] - 14s 21us/step - loss: 7.1649 - mae: 7.1649 - val_loss: 5.2843 - val_mae: 5.2843\n",
      "Epoch 14/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 7.0683 - mae: 7.0683 - val_loss: 5.0006 - val_mae: 5.0006\n",
      "Epoch 15/100\n",
      "648000/648000 [==============================] - 14s 21us/step - loss: 6.8812 - mae: 6.8812 - val_loss: 4.6161 - val_mae: 4.6161\n",
      "Epoch 16/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 6.7275 - mae: 6.7275 - val_loss: 4.9325 - val_mae: 4.9325\n",
      "Epoch 17/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 6.6323 - mae: 6.6323 - val_loss: 4.7980 - val_mae: 4.7980\n",
      "Epoch 18/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 6.5516 - mae: 6.5516 - val_loss: 4.6395 - val_mae: 4.6395\n",
      "Epoch 19/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 6.4577 - mae: 6.4577 - val_loss: 4.6346 - val_mae: 4.6346\n",
      "Epoch 20/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 6.3384 - mae: 6.3384 - val_loss: 4.3512 - val_mae: 4.3512\n",
      "Epoch 21/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 6.2042 - mae: 6.2042 - val_loss: 4.8038 - val_mae: 4.8038\n",
      "Epoch 22/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 6.1380 - mae: 6.1380 - val_loss: 4.4230 - val_mae: 4.4230\n",
      "Epoch 23/100\n",
      "648000/648000 [==============================] - 14s 21us/step - loss: 6.0290 - mae: 6.0290 - val_loss: 4.6015 - val_mae: 4.6015\n",
      "Epoch 24/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.9462 - mae: 5.9462 - val_loss: 4.4211 - val_mae: 4.4211\n",
      "Epoch 25/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.8276 - mae: 5.8276 - val_loss: 4.7223 - val_mae: 4.7223\n",
      "Epoch 26/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.7746 - mae: 5.7746 - val_loss: 4.2005 - val_mae: 4.2005\n",
      "Epoch 27/100\n",
      "648000/648000 [==============================] - 14s 21us/step - loss: 5.6506 - mae: 5.6506 - val_loss: 4.2353 - val_mae: 4.2353\n",
      "Epoch 28/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.5450 - mae: 5.5450 - val_loss: 3.9961 - val_mae: 3.9961\n",
      "Epoch 29/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 5.4603 - mae: 5.4603 - val_loss: 4.8205 - val_mae: 4.8205\n",
      "Epoch 30/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.3992 - mae: 5.3992 - val_loss: 4.2524 - val_mae: 4.2524\n",
      "Epoch 31/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.3813 - mae: 5.3813 - val_loss: 4.4218 - val_mae: 4.4218\n",
      "Epoch 32/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.2531 - mae: 5.2531 - val_loss: 4.0473 - val_mae: 4.0473\n",
      "Epoch 33/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.2031 - mae: 5.2031 - val_loss: 4.0084 - val_mae: 4.0084\n",
      "Epoch 34/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.1326 - mae: 5.1326 - val_loss: 3.5769 - val_mae: 3.5769\n",
      "Epoch 35/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 5.1138 - mae: 5.1138 - val_loss: 4.1726 - val_mae: 4.1726\n",
      "Epoch 36/100\n",
      "648000/648000 [==============================] - 14s 21us/step - loss: 5.0842 - mae: 5.0842 - val_loss: 3.8768 - val_mae: 3.8768\n",
      "Epoch 37/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 5.0033 - mae: 5.0033 - val_loss: 4.2105 - val_mae: 4.2105\n",
      "Epoch 38/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.9469 - mae: 4.9469 - val_loss: 4.1032 - val_mae: 4.1032\n",
      "Epoch 39/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.9404 - mae: 4.9404 - val_loss: 3.8112 - val_mae: 3.8112\n",
      "Epoch 40/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.8878 - mae: 4.8878 - val_loss: 4.0147 - val_mae: 4.0147\n",
      "Epoch 41/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.8903 - mae: 4.8903 - val_loss: 3.9139 - val_mae: 3.9139\n",
      "Epoch 42/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.8106 - mae: 4.8106 - val_loss: 3.8040 - val_mae: 3.8040\n",
      "Epoch 43/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.7887 - mae: 4.7887 - val_loss: 4.0686 - val_mae: 4.0686\n",
      "Epoch 44/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.7636 - mae: 4.7636 - val_loss: 3.5351 - val_mae: 3.5351\n",
      "Epoch 45/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.6806 - mae: 4.6806 - val_loss: 3.5205 - val_mae: 3.5205\n",
      "Epoch 46/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.7682 - mae: 4.7682 - val_loss: 3.6170 - val_mae: 3.6170\n",
      "Epoch 47/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.6958 - mae: 4.6958 - val_loss: 3.6841 - val_mae: 3.6841\n",
      "Epoch 48/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.6398 - mae: 4.6398 - val_loss: 3.8055 - val_mae: 3.8055\n",
      "Epoch 49/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.6188 - mae: 4.6188 - val_loss: 3.4709 - val_mae: 3.4709\n",
      "Epoch 50/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.6287 - mae: 4.6287 - val_loss: 3.6647 - val_mae: 3.6647\n",
      "Epoch 51/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.5907 - mae: 4.5907 - val_loss: 3.7773 - val_mae: 3.7773\n",
      "Epoch 52/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.5362 - mae: 4.5362 - val_loss: 3.4482 - val_mae: 3.4482\n",
      "Epoch 53/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.5620 - mae: 4.5620 - val_loss: 3.6864 - val_mae: 3.6864\n",
      "Epoch 54/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.5295 - mae: 4.5295 - val_loss: 3.8622 - val_mae: 3.8622\n",
      "Epoch 55/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.5377 - mae: 4.5377 - val_loss: 3.5473 - val_mae: 3.5473\n",
      "Epoch 56/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.4594 - mae: 4.4594 - val_loss: 3.3310 - val_mae: 3.3310\n",
      "Epoch 57/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.4717 - mae: 4.4717 - val_loss: 4.4666 - val_mae: 4.4666\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.4362 - mae: 4.4362 - val_loss: 3.4862 - val_mae: 3.4862\n",
      "Epoch 59/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.4822 - mae: 4.4822 - val_loss: 3.9906 - val_mae: 3.9906\n",
      "Epoch 60/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.3947 - mae: 4.3947 - val_loss: 3.2744 - val_mae: 3.2744\n",
      "Epoch 61/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.3829 - mae: 4.3829 - val_loss: 3.4634 - val_mae: 3.4634\n",
      "Epoch 62/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.3583 - mae: 4.3583 - val_loss: 4.0129 - val_mae: 4.0129\n",
      "Epoch 63/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.3465 - mae: 4.3465 - val_loss: 3.3655 - val_mae: 3.3655\n",
      "Epoch 64/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.3554 - mae: 4.3554 - val_loss: 3.2514 - val_mae: 3.2514\n",
      "Epoch 65/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.2984 - mae: 4.2984 - val_loss: 3.6298 - val_mae: 3.6298\n",
      "Epoch 66/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.3190 - mae: 4.3190 - val_loss: 3.5976 - val_mae: 3.5976\n",
      "Epoch 67/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.2445 - mae: 4.2445 - val_loss: 3.7536 - val_mae: 3.7536\n",
      "Epoch 68/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.2939 - mae: 4.2939 - val_loss: 3.5772 - val_mae: 3.5772\n",
      "Epoch 69/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.2766 - mae: 4.2766 - val_loss: 3.4165 - val_mae: 3.4165\n",
      "Epoch 70/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.2711 - mae: 4.2711 - val_loss: 3.5221 - val_mae: 3.5221\n",
      "Epoch 71/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.2282 - mae: 4.2282 - val_loss: 3.1542 - val_mae: 3.1542\n",
      "Epoch 72/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.1844 - mae: 4.1844 - val_loss: 3.3609 - val_mae: 3.3609\n",
      "Epoch 73/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.1870 - mae: 4.1870 - val_loss: 3.9203 - val_mae: 3.9203\n",
      "Epoch 74/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.1695 - mae: 4.1695 - val_loss: 3.2978 - val_mae: 3.2978\n",
      "Epoch 75/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.1564 - mae: 4.1564 - val_loss: 3.4282 - val_mae: 3.4282\n",
      "Epoch 76/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.1253 - mae: 4.1252 - val_loss: 3.8130 - val_mae: 3.8130\n",
      "Epoch 77/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.1185 - mae: 4.1185 - val_loss: 3.0125 - val_mae: 3.0125\n",
      "Epoch 78/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.1055 - mae: 4.1055 - val_loss: 3.1253 - val_mae: 3.1253\n",
      "Epoch 79/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.0977 - mae: 4.0977 - val_loss: 3.1155 - val_mae: 3.1155\n",
      "Epoch 80/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.0682 - mae: 4.0682 - val_loss: 2.8704 - val_mae: 2.8704\n",
      "Epoch 81/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.0858 - mae: 4.0858 - val_loss: 3.6226 - val_mae: 3.6226\n",
      "Epoch 82/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.0893 - mae: 4.0893 - val_loss: 2.9238 - val_mae: 2.9238\n",
      "Epoch 83/100\n",
      "648000/648000 [==============================] - 14s 21us/step - loss: 4.0254 - mae: 4.0254 - val_loss: 3.1432 - val_mae: 3.1432\n",
      "Epoch 84/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.0186 - mae: 4.0186 - val_loss: 3.3430 - val_mae: 3.3430\n",
      "Epoch 85/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 4.0056 - mae: 4.0056 - val_loss: 3.0214 - val_mae: 3.0214\n",
      "Epoch 86/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.0507 - mae: 4.0507 - val_loss: 3.4469 - val_mae: 3.4469\n",
      "Epoch 87/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 4.0074 - mae: 4.0074 - val_loss: 3.0233 - val_mae: 3.0233\n",
      "Epoch 88/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 3.9530 - mae: 3.9530 - val_loss: 3.1293 - val_mae: 3.1293\n",
      "Epoch 89/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.9253 - mae: 3.9253 - val_loss: 3.1644 - val_mae: 3.1644\n",
      "Epoch 90/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.9603 - mae: 3.9603 - val_loss: 2.9627 - val_mae: 2.9627\n",
      "Epoch 91/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.9542 - mae: 3.9542 - val_loss: 3.0185 - val_mae: 3.0185\n",
      "Epoch 92/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.9474 - mae: 3.9474 - val_loss: 2.7889 - val_mae: 2.7889\n",
      "Epoch 93/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.9038 - mae: 3.9038 - val_loss: 3.0394 - val_mae: 3.0394\n",
      "Epoch 94/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 3.9047 - mae: 3.9047 - val_loss: 3.1873 - val_mae: 3.1873\n",
      "Epoch 95/100\n",
      "648000/648000 [==============================] - 13s 20us/step - loss: 3.9010 - mae: 3.9010 - val_loss: 2.9287 - val_mae: 2.9287\n",
      "Epoch 96/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.8873 - mae: 3.8873 - val_loss: 2.7886 - val_mae: 2.7886\n",
      "Epoch 97/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.8875 - mae: 3.8875 - val_loss: 2.9458 - val_mae: 2.9458\n",
      "Epoch 98/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.8348 - mae: 3.8348 - val_loss: 3.0477 - val_mae: 3.0477\n",
      "Epoch 99/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.8893 - mae: 3.8893 - val_loss: 2.9681 - val_mae: 2.9681\n",
      "Epoch 100/100\n",
      "648000/648000 [==============================] - 13s 21us/step - loss: 3.8385 - mae: 3.8385 - val_loss: 2.8202 - val_mae: 2.8202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19b416c2198>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model11 = build_model()\n",
    "model11.fit(train_X, train_Y, epochs=100,callbacks=[ckpt, lr_finder], batch_size=1000, validation_split = 0.2,shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 688500 samples, validate on 121500 samples\n",
      "Epoch 1/100\n",
      "688500/688500 [==============================] - 15s 22us/step - loss: 60.5772 - mae: 60.5772 - val_loss: 52.6091 - val_mae: 52.6091\n",
      "Epoch 2/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 32.6343 - mae: 32.6343 - val_loss: 20.8371 - val_mae: 20.8372\n",
      "Epoch 3/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 17.6451 - mae: 17.6451 - val_loss: 11.7109 - val_mae: 11.7109\n",
      "Epoch 4/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 13.6797 - mae: 13.6797 - val_loss: 9.5707 - val_mae: 9.5707\n",
      "Epoch 5/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 11.8811 - mae: 11.8811 - val_loss: 8.3446 - val_mae: 8.3446\n",
      "Epoch 6/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 10.7800 - mae: 10.7800 - val_loss: 7.0381 - val_mae: 7.0381TA: 0s - loss: 10.7928 - ma - ETA: 0s - loss: 10.7841 - mae: 10.\n",
      "Epoch 7/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 9.9863 - mae: 9.9863 - val_loss: 6.5166 - val_mae: 6.5166\n",
      "Epoch 8/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 9.4786 - mae: 9.4786 - val_loss: 5.9143 - val_mae: 5.9143\n",
      "Epoch 9/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 9.0962 - mae: 9.0962 - val_loss: 5.5362 - val_mae: 5.5362oss: 9.1023 - ma\n",
      "Epoch 10/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 8.7043 - mae: 8.7043 - val_loss: 5.7451 - val_mae: 5.7451\n",
      "Epoch 11/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 8.4611 - mae: 8.4611 - val_loss: 5.7447 - val_mae: 5.7447\n",
      "Epoch 12/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 8.2147 - mae: 8.2147 - val_loss: 5.3953 - val_mae: 5.3953\n",
      "Epoch 13/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 7.9873 - mae: 7.9873 - val_loss: 4.8840 - val_mae: 4.8840\n",
      "Epoch 14/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 7.7915 - mae: 7.7915 - val_loss: 5.5105 - val_mae: 5.5105- mae: 7.\n",
      "Epoch 15/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 7.6155 - mae: 7.6155 - val_loss: 5.7166 - val_mae: 5.7166\n",
      "Epoch 16/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 7.4356 - mae: 7.4356 - val_loss: 4.9968 - val_mae: 4.9968\n",
      "Epoch 17/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 7.2575 - mae: 7.2575 - val_loss: 6.1414 - val_mae: 6.1414\n",
      "Epoch 18/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 7.1401 - mae: 7.1401 - val_loss: 4.9564 - val_mae: 4.9564428 - mae\n",
      "Epoch 19/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 6.9845 - mae: 6.9845 - val_loss: 5.3473 - val_mae: 5.3473\n",
      "Epoch 20/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 6.8237 - mae: 6.8237 - val_loss: 4.2887 - val_mae: 4.2887\n",
      "Epoch 21/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 6.7011 - mae: 6.7011 - val_loss: 4.9527 - val_mae: 4.9527\n",
      "Epoch 22/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 6.5504 - mae: 6.5504 - val_loss: 4.8977 - val_mae: 4.8977 m\n",
      "Epoch 23/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 6.4247 - mae: 6.4247 - val_loss: 4.6697 - val_mae: 4.6697\n",
      "Epoch 24/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 6.3101 - mae: 6.3101 - val_loss: 4.1020 - val_mae: 4.1020\n",
      "Epoch 25/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 6.1926 - mae: 6.1926 - val_loss: 4.0783 - val_mae: 4.0783\n",
      "Epoch 26/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 6.1085 - mae: 6.1085 - val_loss: 4.2544 - val_mae: 4.2544\n",
      "Epoch 27/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 6.0466 - mae: 6.0466 - val_loss: 4.2129 - val_mae: 4.2129\n",
      "Epoch 28/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 5.9283 - mae: 5.9283 - val_loss: 4.6940 - val_mae: 4.6940\n",
      "Epoch 29/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.8400 - mae: 5.8399 - val_loss: 4.0623 - val_mae: 4.0623\n",
      "Epoch 30/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 5.7951 - mae: 5.7950 - val_loss: 3.6648 - val_mae: 3.6648\n",
      "Epoch 31/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.7047 - mae: 5.7047 - val_loss: 4.1004 - val_mae: 4.1004\n",
      "Epoch 32/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.6476 - mae: 5.6476 - val_loss: 3.7945 - val_mae: 3.7945\n",
      "Epoch 33/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.6114 - mae: 5.6114 - val_loss: 4.0971 - val_mae: 4.0971 m\n",
      "Epoch 34/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.5470 - mae: 5.5470 - val_loss: 4.1441 - val_mae: 4.1441\n",
      "Epoch 35/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 5.5181 - mae: 5.5181 - val_loss: 4.5233 - val_mae: 4.5233\n",
      "Epoch 36/100\n",
      "688500/688500 [==============================] - 15s 22us/step - loss: 5.4294 - mae: 5.4294 - val_loss: 3.6695 - val_mae: 3.6695\n",
      "Epoch 37/100\n",
      "688500/688500 [==============================] - 16s 24us/step - loss: 5.3849 - mae: 5.3849 - val_loss: 3.8962 - val_mae: 3.8962\n",
      "Epoch 38/100\n",
      "688500/688500 [==============================] - 16s 23us/step - loss: 5.3488 - mae: 5.3488 - val_loss: 4.0366 - val_mae: 4.0366\n",
      "Epoch 39/100\n",
      "688500/688500 [==============================] - 15s 22us/step - loss: 5.3114 - mae: 5.3114 - val_loss: 3.5423 - val_mae: 3.5423\n",
      "Epoch 40/100\n",
      "688500/688500 [==============================] - 15s 23us/step - loss: 5.2893 - mae: 5.2893 - val_loss: 3.6710 - val_mae: 3.6710\n",
      "Epoch 41/100\n",
      "688500/688500 [==============================] - 15s 22us/step - loss: 5.2355 - mae: 5.2355 - val_loss: 4.0065 - val_mae: 4.0065\n",
      "Epoch 42/100\n",
      "688500/688500 [==============================] - 16s 23us/step - loss: 5.2241 - mae: 5.2241 - val_loss: 3.6750 - val_mae: 3.6750\n",
      "Epoch 43/100\n",
      "688500/688500 [==============================] - 15s 22us/step - loss: 5.1271 - mae: 5.1271 - val_loss: 3.6512 - val_mae: 3.6512\n",
      "Epoch 44/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.0776 - mae: 5.0776 - val_loss: 3.7619 - val_mae: 3.7619\n",
      "Epoch 45/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.0861 - mae: 5.0861 - val_loss: 3.7573 - val_mae: 3.7573\n",
      "Epoch 46/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.0371 - mae: 5.0371 - val_loss: 3.5611 - val_mae: 3.5611\n",
      "Epoch 47/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 5.0204 - mae: 5.0204 - val_loss: 3.4499 - val_mae: 3.4499\n",
      "Epoch 48/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.9964 - mae: 4.9964 - val_loss: 3.9742 - val_mae: 3.9742\n",
      "Epoch 49/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.9725 - mae: 4.9725 - val_loss: 3.3959 - val_mae: 3.3959\n",
      "Epoch 50/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.9522 - mae: 4.9522 - val_loss: 3.5747 - val_mae: 3.5747\n",
      "Epoch 51/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.9124 - mae: 4.9124 - val_loss: 3.5015 - val_mae: 3.5015\n",
      "Epoch 52/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.8839 - mae: 4.8839 - val_loss: 3.8213 - val_mae: 3.8213\n",
      "Epoch 53/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.8503 - mae: 4.8503 - val_loss: 3.5978 - val_mae: 3.5978\n",
      "Epoch 54/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.8416 - mae: 4.8416 - val_loss: 3.9188 - val_mae: 3.9188\n",
      "Epoch 55/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.7880 - mae: 4.7880 - val_loss: 3.2277 - val_mae: 3.2277\n",
      "Epoch 56/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.7752 - mae: 4.7752 - val_loss: 3.4137 - val_mae: 3.4137\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.7953 - mae: 4.7953 - val_loss: 3.4514 - val_mae: 3.4514\n",
      "Epoch 58/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.7359 - mae: 4.7359 - val_loss: 3.5123 - val_mae: 3.5123\n",
      "Epoch 59/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.6747 - mae: 4.6747 - val_loss: 3.3698 - val_mae: 3.3698\n",
      "Epoch 60/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.7008 - mae: 4.7008 - val_loss: 3.6173 - val_mae: 3.6173\n",
      "Epoch 61/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.6551 - mae: 4.6550 - val_loss: 3.2428 - val_mae: 3.2428\n",
      "Epoch 62/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.6617 - mae: 4.6617 - val_loss: 3.7092 - val_mae: 3.7092\n",
      "Epoch 63/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.6251 - mae: 4.6251 - val_loss: 3.2483 - val_mae: 3.2483\n",
      "Epoch 64/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.6254 - mae: 4.6254 - val_loss: 3.3742 - val_mae: 3.3742\n",
      "Epoch 65/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.6328 - mae: 4.6328 - val_loss: 3.3700 - val_mae: 3.3700\n",
      "Epoch 66/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.5924 - mae: 4.5924 - val_loss: 3.1441 - val_mae: 3.1441\n",
      "Epoch 67/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.5458 - mae: 4.5458 - val_loss: 3.2306 - val_mae: 3.2306\n",
      "Epoch 68/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.5472 - mae: 4.5472 - val_loss: 3.1260 - val_mae: 3.1260\n",
      "Epoch 69/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.5026 - mae: 4.5026 - val_loss: 3.1320 - val_mae: 3.1320\n",
      "Epoch 70/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.5245 - mae: 4.5245 - val_loss: 2.9403 - val_mae: 2.9403\n",
      "Epoch 71/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.4959 - mae: 4.4959 - val_loss: 3.2476 - val_mae: 3.2476.50\n",
      "Epoch 72/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.4975 - mae: 4.4975 - val_loss: 3.3123 - val_mae: 3.3123\n",
      "Epoch 73/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.4586 - mae: 4.4586 - val_loss: 3.3614 - val_mae: 3.3614\n",
      "Epoch 74/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.4526 - mae: 4.4526 - val_loss: 3.1687 - val_mae: 3.1687\n",
      "Epoch 75/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.4524 - mae: 4.4524 - val_loss: 3.1174 - val_mae: 3.1174\n",
      "Epoch 76/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.3966 - mae: 4.3966 - val_loss: 3.1775 - val_mae: 3.1775\n",
      "Epoch 77/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.3839 - mae: 4.3839 - val_loss: 2.8525 - val_mae: 2.8525\n",
      "Epoch 78/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.3952 - mae: 4.3952 - val_loss: 3.1327 - val_mae: 3.1327\n",
      "Epoch 79/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.4074 - mae: 4.4074 - val_loss: 2.9178 - val_mae: 2.9178\n",
      "Epoch 80/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.3949 - mae: 4.3949 - val_loss: 3.5492 - val_mae: 3.5492\n",
      "Epoch 81/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.3781 - mae: 4.3781 - val_loss: 3.1112 - val_mae: 3.1112\n",
      "Epoch 82/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.3630 - mae: 4.3630 - val_loss: 2.8489 - val_mae: 2.8489\n",
      "Epoch 83/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.3169 - mae: 4.3169 - val_loss: 2.9047 - val_mae: 2.9047\n",
      "Epoch 84/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.3417 - mae: 4.3417 - val_loss: 3.2719 - val_mae: 3.2719\n",
      "Epoch 85/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.2977 - mae: 4.2977 - val_loss: 3.0373 - val_mae: 3.0373\n",
      "Epoch 86/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.3319 - mae: 4.3319 - val_loss: 3.1958 - val_mae: 3.1958\n",
      "Epoch 87/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.2906 - mae: 4.2906 - val_loss: 3.2389 - val_mae: 3.2389\n",
      "Epoch 88/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.2908 - mae: 4.2908 - val_loss: 2.9295 - val_mae: 2.9295\n",
      "Epoch 89/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.2638 - mae: 4.2638 - val_loss: 3.0097 - val_mae: 3.0097\n",
      "Epoch 90/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.2617 - mae: 4.2617 - val_loss: 2.8102 - val_mae: 2.8102\n",
      "Epoch 91/100\n",
      "688500/688500 [==============================] - 14s 21us/step - loss: 4.2552 - mae: 4.2552 - val_loss: 2.9872 - val_mae: 2.9872\n",
      "Epoch 92/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.2245 - mae: 4.2245 - val_loss: 2.8258 - val_mae: 2.8258s - loss: 4.\n",
      "Epoch 93/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.2329 - mae: 4.2329 - val_loss: 2.9041 - val_mae: 2.9041\n",
      "Epoch 94/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.1990 - mae: 4.1990 - val_loss: 2.9974 - val_mae: 2.9974\n",
      "Epoch 95/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.1986 - mae: 4.1986 - val_loss: 3.0181 - val_mae: 3.0181\n",
      "Epoch 96/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.2054 - mae: 4.2054 - val_loss: 2.9660 - val_mae: 2.9660\n",
      "Epoch 97/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.1697 - mae: 4.1697 - val_loss: 3.2539 - val_mae: 3.2539\n",
      "Epoch 98/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.1864 - mae: 4.1864 - val_loss: 2.9653 - val_mae: 2.9653\n",
      "Epoch 99/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.1643 - mae: 4.1643 - val_loss: 2.9602 - val_mae: 2.9602\n",
      "Epoch 100/100\n",
      "688500/688500 [==============================] - 15s 21us/step - loss: 4.1498 - mae: 4.1498 - val_loss: 3.1675 - val_mae: 3.1675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19b85176630>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "model1.fit(train_X, train_Y, epochs=100,callbacks=[ckpt, lr_finder], batch_size=1000, validation_split = 0.15,shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot_lr()\n",
    "# plt.xlim(1e-3,(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_weights(ckpt_dir +'/ResNetFinetuning_70_valloss2.94.hdf5')\n",
    "pred_test = model1.predict(test_X)\n",
    "y_pred1 = pred_test\n",
    "# model11.load_weights(ckpt_dir +'/ResNetFinetuning_77_valloss4.93.hdf5')\n",
    "# pred_test = model11.predict(test_X)\n",
    "# y_pred2 = pred_test\n",
    "# # model11.load_weights(ckpt_dir +'/ResNetFinetuning_75_valloss0.09.hdf5')\n",
    "# # pred_test = model11.predict(xscaler.transform(test_X))\n",
    "# # y_pred3 = yscaler.inverse_transform(pred_test)\n",
    "# model11.load_weights(ckpt_dir +'/ResNetFinetuning_73_valloss5.01.hdf5')\n",
    "# pred_test = model11.predict(test_X)\n",
    "# y_pred4 = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred1+y_pred2+y_pred4)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>layer_1</th>\n",
       "      <th>layer_2</th>\n",
       "      <th>layer_3</th>\n",
       "      <th>layer_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>254.064392</td>\n",
       "      <td>231.065323</td>\n",
       "      <td>128.873032</td>\n",
       "      <td>89.407043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>156.478638</td>\n",
       "      <td>126.821869</td>\n",
       "      <td>239.739456</td>\n",
       "      <td>99.346886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>151.008453</td>\n",
       "      <td>180.336212</td>\n",
       "      <td>274.262939</td>\n",
       "      <td>161.574860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92.844887</td>\n",
       "      <td>234.588516</td>\n",
       "      <td>184.294617</td>\n",
       "      <td>86.483749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>271.374878</td>\n",
       "      <td>294.000183</td>\n",
       "      <td>245.959915</td>\n",
       "      <td>272.282257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     layer_1     layer_2     layer_3     layer_4\n",
       "0   0  254.064392  231.065323  128.873032   89.407043\n",
       "1   1  156.478638  126.821869  239.739456   99.346886\n",
       "2   2  151.008453  180.336212  274.262939  161.574860\n",
       "3   3   92.844887  234.588516  184.294617   86.483749\n",
       "4   4  271.374878  294.000183  245.959915  272.282257"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample.iloc[:,1:] = y_pred1\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"sample_sub1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
