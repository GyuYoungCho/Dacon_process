{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras_process6.ipynb","provenance":[],"authorship_tag":"ABX9TyOQ2i86i1TPrDNIuPGTNfk2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MpKGaXhsW3Hc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yl9ouvgzZ_Vg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"da2cf914-218b-4c82-8c77-af491ae0b1f7","executionInfo":{"status":"ok","timestamp":1580490042177,"user_tz":-540,"elapsed":32086,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EEFS_G3aaAST","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import warnings\n","import numpy as np\n","warnings.filterwarnings('ignore')\n","train = pd.read_csv('/gdrive/My Drive/Data/trains.csv')\n","test = pd.read_csv('/gdrive/My Drive/Data/test.csv')\n","\n","for col in train.columns:\n","    col_type = train[col].dtypes\n","    min1 = train[col].min()\n","    max1 = train[col].max()\n","    if str(col_type)[:3] == 'int':\n","        train[col] = train[col].astype(np.int16)\n","    else:\n","        if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n","            train[col] = train[col].astype(np.float16)\n","        elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n","            train[col] = train[col].astype(np.float32)\n","        else:\n","            train[col] = train[col].astype(np.float64)\n","train = train.sample(frac=1,random_state=123).reset_index(drop=True)\n","train_X = train.iloc[:,4:]\n","train_Y = train.iloc[:,0:4]\n","test_X = test.iloc[:,1:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9GEPnZhacQn","colab_type":"code","colab":{}},"source":["import keras\n","from keras import backend as K\n","from keras.models import Sequential, Model\n","from keras.utils import get_custom_objects\n","from keras.layers import *\n","from keras import optimizers\n","from keras import activations\n","\n","\n","def res_unit(inputs, channels):\n","    x = BatchNormalization()(inputs)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, padding='same', use_bias=False)(x)\n","    added = Add()([inputs, x])\n","    return added\n","\n","def res_unit_stride(inputs, channels):\n","    x = BatchNormalization()(inputs)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, padding='same', use_bias=False)(x)\n","    conv = Conv1D(channels, kernel_size=1, strides=2, padding='same', use_bias=False)(inputs)\n","    added = Add()([conv, x])\n","    return added\n","\n","class mish(Activation):\n","    def __init__(self, activation, **kwargs):\n","        super(mish, self).__init__(activation, **kwargs)\n","        self.__name__ = 'mish'\n","\n","def Mish(x):\n","    return x*K.tanh(K.softplus(x))\n","\n","get_custom_objects().update({'mish': mish(Mish)}) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrC8HUgvate3","colab_type":"code","colab":{}},"source":["seq_in = Input(shape=(226,1))\n","x = Conv1D(16, kernel_size=3, activation='relu', padding='valid')(seq_in)\n","x = MaxPooling1D(2, padding='valid')(x)\n","x =  res_unit(x, 16)\n","x =  res_unit(x, 16)\n","x =  res_unit(x, 16)\n","x =  res_unit_stride(x, 32)\n","x =  res_unit(x, 32)\n","x =  res_unit(x, 32)\n","x =  res_unit(x, 32)\n","x =  res_unit_stride(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit_stride(x, 128)\n","x =  res_unit(x, 128)\n","x =  res_unit(x, 128)\n","x =  res_unit(x, 128)\n","x =  res_unit_stride(x, 256)\n","x =  res_unit(x, 256)\n","x =  res_unit(x, 256)\n","x = BatchNormalization()(x)\n","x = Activation('mish')(x)\n","x = GlobalAveragePooling1D()(x)\n","x = Dense(4, kernel_initializer='he_normal', activation='linear')(x)\n","seq_out = x\n","\n","# # # for meta_cols\n","# # meta_in = Input(shape=(4,))\n","# # meta_out = Dense(4, kernel_initializer='he_normal', activation='mish')(meta_in)\n","\n","# # Concat\n","# merges = Concatenate()([seq_out, meta_out])\n","\n","# # decode\n","# seq_decode = Dense(226, kernel_initializer='he_normal')(merges)\n","# seq_decode = Reshape((226,1))(seq_decode)\n","# meta_decode = Dense(4, kernel_initializer='he_normal')(merges)\n","\n","model = Model(inputs=seq_in , outputs=seq_out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"65APLqsHejQe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"14b7bfee-1f73-4dee-af0a-c2063a0e8a9f","executionInfo":{"status":"ok","timestamp":1580492174566,"user_tz":-540,"elapsed":714,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["model.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 226, 1)       0                                            \n","__________________________________________________________________________________________________\n","conv1d_44 (Conv1D)              (None, 224, 16)      64          input_2[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling1d_2 (MaxPooling1D)  (None, 112, 16)      0           conv1d_44[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 112, 16)      64          max_pooling1d_2[0][0]            \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 112, 16)      0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_45 (Conv1D)              (None, 112, 16)      768         activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 112, 16)      64          conv1d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 112, 16)      0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_46 (Conv1D)              (None, 112, 16)      768         activation_42[0][0]              \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 112, 16)      0           max_pooling1d_2[0][0]            \n","                                                                 conv1d_46[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 112, 16)      64          add_20[0][0]                     \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 112, 16)      0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_47 (Conv1D)              (None, 112, 16)      768         activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 112, 16)      64          conv1d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 112, 16)      0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_48 (Conv1D)              (None, 112, 16)      768         activation_44[0][0]              \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 112, 16)      0           add_20[0][0]                     \n","                                                                 conv1d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 112, 16)      64          add_21[0][0]                     \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 112, 16)      0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_49 (Conv1D)              (None, 112, 16)      768         activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 112, 16)      64          conv1d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 112, 16)      0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_50 (Conv1D)              (None, 112, 16)      768         activation_46[0][0]              \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 112, 16)      0           add_21[0][0]                     \n","                                                                 conv1d_50[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 112, 16)      64          add_22[0][0]                     \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 112, 16)      0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_51 (Conv1D)              (None, 56, 32)       1536        activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 56, 32)       128         conv1d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 56, 32)       0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_53 (Conv1D)              (None, 56, 32)       512         add_22[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_52 (Conv1D)              (None, 56, 32)       3072        activation_48[0][0]              \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, 56, 32)       0           conv1d_53[0][0]                  \n","                                                                 conv1d_52[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 56, 32)       128         add_23[0][0]                     \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 56, 32)       0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_54 (Conv1D)              (None, 56, 32)       3072        activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 56, 32)       128         conv1d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 56, 32)       0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_55 (Conv1D)              (None, 56, 32)       3072        activation_50[0][0]              \n","__________________________________________________________________________________________________\n","add_24 (Add)                    (None, 56, 32)       0           add_23[0][0]                     \n","                                                                 conv1d_55[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 56, 32)       128         add_24[0][0]                     \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 56, 32)       0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_56 (Conv1D)              (None, 56, 32)       3072        activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 56, 32)       128         conv1d_56[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 56, 32)       0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_57 (Conv1D)              (None, 56, 32)       3072        activation_52[0][0]              \n","__________________________________________________________________________________________________\n","add_25 (Add)                    (None, 56, 32)       0           add_24[0][0]                     \n","                                                                 conv1d_57[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 56, 32)       128         add_25[0][0]                     \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 56, 32)       0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_58 (Conv1D)              (None, 56, 32)       3072        activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 56, 32)       128         conv1d_58[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 56, 32)       0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_59 (Conv1D)              (None, 56, 32)       3072        activation_54[0][0]              \n","__________________________________________________________________________________________________\n","add_26 (Add)                    (None, 56, 32)       0           add_25[0][0]                     \n","                                                                 conv1d_59[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 56, 32)       128         add_26[0][0]                     \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 56, 32)       0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_60 (Conv1D)              (None, 28, 64)       6144        activation_55[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 28, 64)       256         conv1d_60[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 28, 64)       0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_62 (Conv1D)              (None, 28, 64)       2048        add_26[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_61 (Conv1D)              (None, 28, 64)       12288       activation_56[0][0]              \n","__________________________________________________________________________________________________\n","add_27 (Add)                    (None, 28, 64)       0           conv1d_62[0][0]                  \n","                                                                 conv1d_61[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 28, 64)       256         add_27[0][0]                     \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 28, 64)       0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_63 (Conv1D)              (None, 28, 64)       12288       activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 28, 64)       256         conv1d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 28, 64)       0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_64 (Conv1D)              (None, 28, 64)       12288       activation_58[0][0]              \n","__________________________________________________________________________________________________\n","add_28 (Add)                    (None, 28, 64)       0           add_27[0][0]                     \n","                                                                 conv1d_64[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 28, 64)       256         add_28[0][0]                     \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 28, 64)       0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_65 (Conv1D)              (None, 28, 64)       12288       activation_59[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 28, 64)       256         conv1d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 28, 64)       0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_66 (Conv1D)              (None, 28, 64)       12288       activation_60[0][0]              \n","__________________________________________________________________________________________________\n","add_29 (Add)                    (None, 28, 64)       0           add_28[0][0]                     \n","                                                                 conv1d_66[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 28, 64)       256         add_29[0][0]                     \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 28, 64)       0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_67 (Conv1D)              (None, 28, 64)       12288       activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 28, 64)       256         conv1d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 28, 64)       0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_68 (Conv1D)              (None, 28, 64)       12288       activation_62[0][0]              \n","__________________________________________________________________________________________________\n","add_30 (Add)                    (None, 28, 64)       0           add_29[0][0]                     \n","                                                                 conv1d_68[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 28, 64)       256         add_30[0][0]                     \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 28, 64)       0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_69 (Conv1D)              (None, 28, 64)       12288       activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 28, 64)       256         conv1d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 28, 64)       0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_70 (Conv1D)              (None, 28, 64)       12288       activation_64[0][0]              \n","__________________________________________________________________________________________________\n","add_31 (Add)                    (None, 28, 64)       0           add_30[0][0]                     \n","                                                                 conv1d_70[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 28, 64)       256         add_31[0][0]                     \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 28, 64)       0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_71 (Conv1D)              (None, 14, 128)      24576       activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 14, 128)      512         conv1d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 14, 128)      0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_73 (Conv1D)              (None, 14, 128)      8192        add_31[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_72 (Conv1D)              (None, 14, 128)      49152       activation_66[0][0]              \n","__________________________________________________________________________________________________\n","add_32 (Add)                    (None, 14, 128)      0           conv1d_73[0][0]                  \n","                                                                 conv1d_72[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 14, 128)      512         add_32[0][0]                     \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 14, 128)      0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_74 (Conv1D)              (None, 14, 128)      49152       activation_67[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 14, 128)      512         conv1d_74[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 14, 128)      0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_75 (Conv1D)              (None, 14, 128)      49152       activation_68[0][0]              \n","__________________________________________________________________________________________________\n","add_33 (Add)                    (None, 14, 128)      0           add_32[0][0]                     \n","                                                                 conv1d_75[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 14, 128)      512         add_33[0][0]                     \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 14, 128)      0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_76 (Conv1D)              (None, 14, 128)      49152       activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 14, 128)      512         conv1d_76[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 14, 128)      0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_77 (Conv1D)              (None, 14, 128)      49152       activation_70[0][0]              \n","__________________________________________________________________________________________________\n","add_34 (Add)                    (None, 14, 128)      0           add_33[0][0]                     \n","                                                                 conv1d_77[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 14, 128)      512         add_34[0][0]                     \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 14, 128)      0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_78 (Conv1D)              (None, 14, 128)      49152       activation_71[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 14, 128)      512         conv1d_78[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 14, 128)      0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_79 (Conv1D)              (None, 14, 128)      49152       activation_72[0][0]              \n","__________________________________________________________________________________________________\n","add_35 (Add)                    (None, 14, 128)      0           add_34[0][0]                     \n","                                                                 conv1d_79[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 14, 128)      512         add_35[0][0]                     \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 14, 128)      0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_80 (Conv1D)              (None, 7, 256)       98304       activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 7, 256)       1024        conv1d_80[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 7, 256)       0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_82 (Conv1D)              (None, 7, 256)       32768       add_35[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_81 (Conv1D)              (None, 7, 256)       196608      activation_74[0][0]              \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 7, 256)       0           conv1d_82[0][0]                  \n","                                                                 conv1d_81[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 7, 256)       1024        add_36[0][0]                     \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 7, 256)       0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_83 (Conv1D)              (None, 7, 256)       196608      activation_75[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 7, 256)       1024        conv1d_83[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 7, 256)       0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_84 (Conv1D)              (None, 7, 256)       196608      activation_76[0][0]              \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 7, 256)       0           add_36[0][0]                     \n","                                                                 conv1d_84[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 7, 256)       1024        add_37[0][0]                     \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 7, 256)       0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_85 (Conv1D)              (None, 7, 256)       196608      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 7, 256)       1024        conv1d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 7, 256)       0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_86 (Conv1D)              (None, 7, 256)       196608      activation_78[0][0]              \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 7, 256)       0           add_37[0][0]                     \n","                                                                 conv1d_86[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 7, 256)       1024        add_38[0][0]                     \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 7, 256)       0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","global_average_pooling1d_2 (Glo (None, 256)          0           activation_79[0][0]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 4)            1028        global_average_pooling1d_2[0][0] \n","==================================================================================================\n","Total params: 1,653,252\n","Trainable params: 1,646,116\n","Non-trainable params: 7,136\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZEgrWEhkXRP","colab_type":"code","colab":{}},"source":["op = optimizers.Adam(lr = 0.001 , beta_1 = 0.9, beta_2 = 0.999)\n","model.compile(loss='mae', optimizer=op, metrics=['mae'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdYgekbgfxkb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c3352757-2e99-474c-ad64-9643224179dc","executionInfo":{"status":"ok","timestamp":1580492180706,"user_tz":-540,"elapsed":973,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["from keras.callbacks import Callback\n","import matplotlib.pyplot as plt\n","import keras.backend as K\n","plt.figure(figsize = (13,8))\n","class LRFinder(Callback):\n","    \n","    def __init__(self, min_lr=1e-5, max_lr=1e-2, steps_per_epoch=None, epochs=None):\n","        super().__init__()\n","        self.total_iterations = steps_per_epoch * epochs\n","        self.min_lr = min_lr\n","        self.max_lr = max_lr\n","        self.iteration = 0\n","        self.history = {}\n","        \n","    def clr(self):\n","        '''Calculate the learning rate.'''\n","        x = self.iteration / self.total_iterations \n","        return self.min_lr + (self.max_lr-self.min_lr) * x\n","        \n","    def on_train_begin(self, logs=None):\n","        '''Initialize the learning rate to the minimum value at the start of training.'''\n","        logs = logs or {}\n","        K.set_value(self.model.optimizer.lr, self.min_lr)\n","        \n","    def on_batch_end(self, epoch, logs=None):\n","        '''Record previous batch statistics and update the learning rate.'''\n","        logs = logs or {}\n","        self.iteration += 1\n","\n","        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n","        self.history.setdefault('iterations', []).append(self.iteration)\n","\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","            \n","        K.set_value(self.model.optimizer.lr, self.clr())\n","    def plot_lr(self):\n","        '''Helper function to quickly inspect the learning rate schedule.'''\n","        plt.plot(self.history['iterations'], self.history['lr'])\n","        plt.yscale('log')\n","        plt.xlabel('Iteration')\n","        plt.ylabel('Learning rate')\n","        \n","    def plot_loss(self):\n","        '''Helper function to quickly observe the learning rate experiment results.'''\n","        plt.plot(self.history['lr'], self.history['loss'])\n","        plt.xscale('log')\n","        plt.xlabel('Learning rate')\n","        plt.ylabel('Loss')"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 936x576 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"tNb30svKkJrb","colab_type":"code","colab":{}},"source":["epochs = 100\n","batch_size = 1000\n","epoch_size = len(train_X)\n","\n","lr_finder = LRFinder(min_lr=1e-5, \n","                     max_lr=1e-2, \n","                     steps_per_epoch=np.ceil(epoch_size/batch_size), \n","                     epochs=epochs)\n","\n","early_stop = keras.callbacks.EarlyStopping(patience=20, monitor='val_loss')\n","\n","ckpt_dir = '/gdrive/My Drive/ckpt2'\n","ckpt_path = ckpt_dir + '/Finetuning_{epoch:02d}_valloss{val_loss:.2f}.hdf5'\n","ckpt = keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFsZtYSHjzRT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"dfc5a96e-10f2-451d-a3ca-238b7ce58695","executionInfo":{"status":"ok","timestamp":1580518122227,"user_tz":-540,"elapsed":25518407,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["train_X = train.iloc[:,4:]\n","train_X = np.expand_dims(train_X, axis=2)\n","model.fit(train_X, train_Y, epochs=200, batch_size=1000, callbacks=[ckpt,  lr_finder], validation_split=0.1,shuffle=True)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train on 729000 samples, validate on 81000 samples\n","Epoch 1/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 95.8844 - mean_absolute_error: 95.8844 - val_loss: 72.0808 - val_mean_absolute_error: 72.0808\n","Epoch 2/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 57.0521 - mean_absolute_error: 57.0521 - val_loss: 41.4698 - val_mean_absolute_error: 41.4698\n","Epoch 3/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 23.1315 - mean_absolute_error: 23.1315 - val_loss: 12.9430 - val_mean_absolute_error: 12.9430\n","Epoch 4/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 6.5404 - mean_absolute_error: 6.5404 - val_loss: 6.0591 - val_mean_absolute_error: 6.0591\n","Epoch 5/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 4.7147 - mean_absolute_error: 4.7147 - val_loss: 4.5473 - val_mean_absolute_error: 4.5473\n","Epoch 6/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 4.1331 - mean_absolute_error: 4.1331 - val_loss: 3.7586 - val_mean_absolute_error: 3.7586\n","Epoch 7/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 3.8444 - mean_absolute_error: 3.8444 - val_loss: 4.3995 - val_mean_absolute_error: 4.3995\n","Epoch 8/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 3.6017 - mean_absolute_error: 3.6017 - val_loss: 3.5342 - val_mean_absolute_error: 3.5342\n","Epoch 9/200\n","729000/729000 [==============================] - 129s 178us/step - loss: 3.5183 - mean_absolute_error: 3.5183 - val_loss: 5.8881 - val_mean_absolute_error: 5.8881\n","Epoch 10/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 3.3181 - mean_absolute_error: 3.3181 - val_loss: 3.2970 - val_mean_absolute_error: 3.2970\n","Epoch 11/200\n","729000/729000 [==============================] - 130s 178us/step - loss: 3.2655 - mean_absolute_error: 3.2655 - val_loss: 7.0760 - val_mean_absolute_error: 7.0760\n","Epoch 12/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 3.1419 - mean_absolute_error: 3.1419 - val_loss: 3.5660 - val_mean_absolute_error: 3.5660\n","Epoch 13/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 3.0353 - mean_absolute_error: 3.0353 - val_loss: 3.4945 - val_mean_absolute_error: 3.4945\n","Epoch 14/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.9167 - mean_absolute_error: 2.9167 - val_loss: 3.5681 - val_mean_absolute_error: 3.5681\n","Epoch 15/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.9019 - mean_absolute_error: 2.9019 - val_loss: 3.1157 - val_mean_absolute_error: 3.1157\n","Epoch 16/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.9180 - mean_absolute_error: 2.9180 - val_loss: 2.3703 - val_mean_absolute_error: 2.3703\n","Epoch 17/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.7537 - mean_absolute_error: 2.7537 - val_loss: 3.1653 - val_mean_absolute_error: 3.1653\n","Epoch 18/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.7574 - mean_absolute_error: 2.7574 - val_loss: 2.6611 - val_mean_absolute_error: 2.6611\n","Epoch 19/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.6867 - mean_absolute_error: 2.6867 - val_loss: 3.6143 - val_mean_absolute_error: 3.6143\n","Epoch 20/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.6679 - mean_absolute_error: 2.6679 - val_loss: 10.7031 - val_mean_absolute_error: 10.7031\n","Epoch 21/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.5496 - mean_absolute_error: 2.5496 - val_loss: 2.5589 - val_mean_absolute_error: 2.5589\n","Epoch 22/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.6412 - mean_absolute_error: 2.6412 - val_loss: 11.1373 - val_mean_absolute_error: 11.1373\n","Epoch 23/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.4334 - mean_absolute_error: 2.4334 - val_loss: 3.8635 - val_mean_absolute_error: 3.8635\n","Epoch 24/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.4919 - mean_absolute_error: 2.4919 - val_loss: 6.3598 - val_mean_absolute_error: 6.3598\n","Epoch 25/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.4087 - mean_absolute_error: 2.4087 - val_loss: 10.5218 - val_mean_absolute_error: 10.5218\n","Epoch 26/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 2.3882 - mean_absolute_error: 2.3882 - val_loss: 2.6885 - val_mean_absolute_error: 2.6885\n","Epoch 27/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.3705 - mean_absolute_error: 2.3705 - val_loss: 5.2136 - val_mean_absolute_error: 5.2136\n","Epoch 28/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.2624 - mean_absolute_error: 2.2624 - val_loss: 3.8700 - val_mean_absolute_error: 3.8700\n","Epoch 29/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 2.2884 - mean_absolute_error: 2.2884 - val_loss: 2.3076 - val_mean_absolute_error: 2.3076\n","Epoch 30/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.2254 - mean_absolute_error: 2.2254 - val_loss: 2.4153 - val_mean_absolute_error: 2.4153\n","Epoch 31/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 2.1409 - mean_absolute_error: 2.1409 - val_loss: 2.0145 - val_mean_absolute_error: 2.0145\n","Epoch 32/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 2.0761 - mean_absolute_error: 2.0761 - val_loss: 1.8026 - val_mean_absolute_error: 1.8026\n","Epoch 33/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.9320 - mean_absolute_error: 1.9320 - val_loss: 1.4836 - val_mean_absolute_error: 1.4836\n","Epoch 34/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 2.0164 - mean_absolute_error: 2.0164 - val_loss: 28.7560 - val_mean_absolute_error: 28.7560\n","Epoch 35/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.8311 - mean_absolute_error: 1.8311 - val_loss: 14.4310 - val_mean_absolute_error: 14.4310\n","Epoch 36/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.7465 - mean_absolute_error: 1.7465 - val_loss: 3.9630 - val_mean_absolute_error: 3.9630\n","Epoch 37/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.7130 - mean_absolute_error: 1.7130 - val_loss: 4.4320 - val_mean_absolute_error: 4.4320\n","Epoch 38/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.6720 - mean_absolute_error: 1.6720 - val_loss: 2.2449 - val_mean_absolute_error: 2.2449\n","Epoch 39/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.5527 - mean_absolute_error: 1.5527 - val_loss: 3.8532 - val_mean_absolute_error: 3.8532\n","Epoch 40/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.4650 - mean_absolute_error: 1.4650 - val_loss: 44.9331 - val_mean_absolute_error: 44.9331\n","Epoch 41/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.4444 - mean_absolute_error: 1.4444 - val_loss: 9.1005 - val_mean_absolute_error: 9.1005\n","Epoch 42/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.3345 - mean_absolute_error: 1.3345 - val_loss: 16.0468 - val_mean_absolute_error: 16.0468\n","Epoch 43/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.2526 - mean_absolute_error: 1.2526 - val_loss: 44.4722 - val_mean_absolute_error: 44.4722\n","Epoch 44/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.2899 - mean_absolute_error: 1.2899 - val_loss: 2.5604 - val_mean_absolute_error: 2.5604\n","Epoch 45/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.2136 - mean_absolute_error: 1.2136 - val_loss: 10.1627 - val_mean_absolute_error: 10.1627\n","Epoch 46/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.2146 - mean_absolute_error: 1.2146 - val_loss: 4.4601 - val_mean_absolute_error: 4.4601\n","Epoch 47/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.1695 - mean_absolute_error: 1.1695 - val_loss: 39.0766 - val_mean_absolute_error: 39.0766\n","Epoch 48/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.1218 - mean_absolute_error: 1.1218 - val_loss: 7.3664 - val_mean_absolute_error: 7.3664\n","Epoch 49/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.0981 - mean_absolute_error: 1.0981 - val_loss: 26.1496 - val_mean_absolute_error: 26.1496\n","Epoch 50/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.1269 - mean_absolute_error: 1.1269 - val_loss: 2.3735 - val_mean_absolute_error: 2.3735\n","Epoch 51/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.1450 - mean_absolute_error: 1.1450 - val_loss: 11.3736 - val_mean_absolute_error: 11.3736\n","Epoch 52/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.0339 - mean_absolute_error: 1.0339 - val_loss: 16.0368 - val_mean_absolute_error: 16.0368\n","Epoch 53/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 1.0699 - mean_absolute_error: 1.0699 - val_loss: 5.3777 - val_mean_absolute_error: 5.3777\n","Epoch 54/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 1.0702 - mean_absolute_error: 1.0702 - val_loss: 36.5808 - val_mean_absolute_error: 36.5808\n","Epoch 55/200\n","729000/729000 [==============================] - 130s 178us/step - loss: 1.0759 - mean_absolute_error: 1.0759 - val_loss: 15.1201 - val_mean_absolute_error: 15.1201\n","Epoch 56/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 1.0693 - mean_absolute_error: 1.0693 - val_loss: 25.9727 - val_mean_absolute_error: 25.9727\n","Epoch 57/200\n","729000/729000 [==============================] - 130s 178us/step - loss: 1.0947 - mean_absolute_error: 1.0947 - val_loss: 37.3856 - val_mean_absolute_error: 37.3856\n","Epoch 58/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.9859 - mean_absolute_error: 0.9859 - val_loss: 26.5882 - val_mean_absolute_error: 26.5882\n","Epoch 59/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.0234 - mean_absolute_error: 1.0234 - val_loss: 32.7579 - val_mean_absolute_error: 32.7579\n","Epoch 60/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.0597 - mean_absolute_error: 1.0597 - val_loss: 25.0009 - val_mean_absolute_error: 25.0009\n","Epoch 61/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.9781 - mean_absolute_error: 0.9781 - val_loss: 22.8514 - val_mean_absolute_error: 22.8514\n","Epoch 62/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.9882 - mean_absolute_error: 0.9882 - val_loss: 46.7866 - val_mean_absolute_error: 46.7866\n","Epoch 63/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.0403 - mean_absolute_error: 1.0403 - val_loss: 41.1647 - val_mean_absolute_error: 41.1647\n","Epoch 64/200\n","729000/729000 [==============================] - 129s 176us/step - loss: 0.9953 - mean_absolute_error: 0.9953 - val_loss: 11.8750 - val_mean_absolute_error: 11.8750\n","Epoch 65/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.0108 - mean_absolute_error: 1.0108 - val_loss: 42.2417 - val_mean_absolute_error: 42.2417\n","Epoch 66/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9776 - mean_absolute_error: 0.9776 - val_loss: 27.4502 - val_mean_absolute_error: 27.4502\n","Epoch 67/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 1.0114 - mean_absolute_error: 1.0114 - val_loss: 67.7204 - val_mean_absolute_error: 67.7204\n","Epoch 68/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9132 - mean_absolute_error: 0.9132 - val_loss: 27.5895 - val_mean_absolute_error: 27.5895\n","Epoch 69/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9940 - mean_absolute_error: 0.9940 - val_loss: 41.4221 - val_mean_absolute_error: 41.4221\n","Epoch 70/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9657 - mean_absolute_error: 0.9657 - val_loss: 58.0995 - val_mean_absolute_error: 58.0995\n","Epoch 71/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 1.0355 - mean_absolute_error: 1.0355 - val_loss: 35.2208 - val_mean_absolute_error: 35.2208\n","Epoch 72/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9921 - mean_absolute_error: 0.9921 - val_loss: 62.2646 - val_mean_absolute_error: 62.2646\n","Epoch 73/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9479 - mean_absolute_error: 0.9479 - val_loss: 41.1740 - val_mean_absolute_error: 41.1740\n","Epoch 74/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9673 - mean_absolute_error: 0.9673 - val_loss: 49.4739 - val_mean_absolute_error: 49.4739\n","Epoch 75/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 0.9954 - mean_absolute_error: 0.9954 - val_loss: 43.2936 - val_mean_absolute_error: 43.2936\n","Epoch 76/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.9063 - mean_absolute_error: 0.9063 - val_loss: 36.4415 - val_mean_absolute_error: 36.4415\n","Epoch 77/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.9396 - mean_absolute_error: 0.9396 - val_loss: 33.4231 - val_mean_absolute_error: 33.4231\n","Epoch 78/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.9614 - mean_absolute_error: 0.9614 - val_loss: 53.1447 - val_mean_absolute_error: 53.1447\n","Epoch 79/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.8897 - mean_absolute_error: 0.8897 - val_loss: 58.2587 - val_mean_absolute_error: 58.2587\n","Epoch 80/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9091 - mean_absolute_error: 0.9091 - val_loss: 35.0196 - val_mean_absolute_error: 35.0196\n","Epoch 81/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9373 - mean_absolute_error: 0.9373 - val_loss: 57.0006 - val_mean_absolute_error: 57.0006\n","Epoch 82/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 0.9232 - mean_absolute_error: 0.9232 - val_loss: 67.5098 - val_mean_absolute_error: 67.5098\n","Epoch 83/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.9161 - mean_absolute_error: 0.9161 - val_loss: 53.3459 - val_mean_absolute_error: 53.3459\n","Epoch 84/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8797 - mean_absolute_error: 0.8797 - val_loss: 54.4640 - val_mean_absolute_error: 54.4640\n","Epoch 85/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.9187 - mean_absolute_error: 0.9187 - val_loss: 51.6758 - val_mean_absolute_error: 51.6758\n","Epoch 86/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.9413 - mean_absolute_error: 0.9413 - val_loss: 86.6598 - val_mean_absolute_error: 86.6598\n","Epoch 87/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8956 - mean_absolute_error: 0.8956 - val_loss: 54.9033 - val_mean_absolute_error: 54.9033\n","Epoch 88/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8668 - mean_absolute_error: 0.8668 - val_loss: 68.4923 - val_mean_absolute_error: 68.4923\n","Epoch 89/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8720 - mean_absolute_error: 0.8720 - val_loss: 39.9201 - val_mean_absolute_error: 39.9201\n","Epoch 90/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8694 - mean_absolute_error: 0.8694 - val_loss: 68.6190 - val_mean_absolute_error: 68.6190\n","Epoch 91/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.8797 - mean_absolute_error: 0.8797 - val_loss: 98.4889 - val_mean_absolute_error: 98.4889\n","Epoch 92/200\n","729000/729000 [==============================] - 129s 176us/step - loss: 0.8886 - mean_absolute_error: 0.8886 - val_loss: 61.4070 - val_mean_absolute_error: 61.4070\n","Epoch 93/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.8739 - mean_absolute_error: 0.8739 - val_loss: 77.0366 - val_mean_absolute_error: 77.0366\n","Epoch 94/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8560 - mean_absolute_error: 0.8560 - val_loss: 51.2793 - val_mean_absolute_error: 51.2793\n","Epoch 95/200\n","729000/729000 [==============================] - 128s 176us/step - loss: 0.8765 - mean_absolute_error: 0.8765 - val_loss: 90.9271 - val_mean_absolute_error: 90.9271\n","Epoch 96/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8799 - mean_absolute_error: 0.8799 - val_loss: 58.0950 - val_mean_absolute_error: 58.0950\n","Epoch 97/200\n","729000/729000 [==============================] - 129s 178us/step - loss: 0.8358 - mean_absolute_error: 0.8358 - val_loss: 82.6162 - val_mean_absolute_error: 82.6162\n","Epoch 98/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8286 - mean_absolute_error: 0.8286 - val_loss: 71.4929 - val_mean_absolute_error: 71.4929\n","Epoch 99/200\n","729000/729000 [==============================] - 130s 178us/step - loss: 0.8461 - mean_absolute_error: 0.8461 - val_loss: 72.3732 - val_mean_absolute_error: 72.3732\n","Epoch 100/200\n","729000/729000 [==============================] - 130s 178us/step - loss: 0.8463 - mean_absolute_error: 0.8463 - val_loss: 75.8694 - val_mean_absolute_error: 75.8694\n","Epoch 101/200\n","729000/729000 [==============================] - 130s 178us/step - loss: 0.8212 - mean_absolute_error: 0.8212 - val_loss: 79.4691 - val_mean_absolute_error: 79.4691\n","Epoch 102/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8098 - mean_absolute_error: 0.8098 - val_loss: 77.6935 - val_mean_absolute_error: 77.6935\n","Epoch 103/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8559 - mean_absolute_error: 0.8559 - val_loss: 54.4151 - val_mean_absolute_error: 54.4151\n","Epoch 104/200\n","729000/729000 [==============================] - 129s 178us/step - loss: 0.8105 - mean_absolute_error: 0.8105 - val_loss: 46.3055 - val_mean_absolute_error: 46.3055\n","Epoch 105/200\n","729000/729000 [==============================] - 129s 178us/step - loss: 0.8061 - mean_absolute_error: 0.8061 - val_loss: 63.3554 - val_mean_absolute_error: 63.3554\n","Epoch 106/200\n","729000/729000 [==============================] - 129s 178us/step - loss: 0.8177 - mean_absolute_error: 0.8177 - val_loss: 68.7766 - val_mean_absolute_error: 68.7766\n","Epoch 107/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8280 - mean_absolute_error: 0.8280 - val_loss: 81.2283 - val_mean_absolute_error: 81.2283\n","Epoch 108/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8063 - mean_absolute_error: 0.8063 - val_loss: 79.1927 - val_mean_absolute_error: 79.1927\n","Epoch 109/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8244 - mean_absolute_error: 0.8244 - val_loss: 91.5417 - val_mean_absolute_error: 91.5417\n","Epoch 110/200\n","729000/729000 [==============================] - 129s 177us/step - loss: 0.8173 - mean_absolute_error: 0.8173 - val_loss: 63.7484 - val_mean_absolute_error: 63.7484\n","Epoch 111/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8210 - mean_absolute_error: 0.8210 - val_loss: 83.1275 - val_mean_absolute_error: 83.1275\n","Epoch 112/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8069 - mean_absolute_error: 0.8069 - val_loss: 102.4122 - val_mean_absolute_error: 102.4122\n","Epoch 113/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 0.8507 - mean_absolute_error: 0.8507 - val_loss: 99.6599 - val_mean_absolute_error: 99.6599\n","Epoch 114/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 0.8128 - mean_absolute_error: 0.8128 - val_loss: 71.9570 - val_mean_absolute_error: 71.9570\n","Epoch 115/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.8103 - mean_absolute_error: 0.8103 - val_loss: 105.3687 - val_mean_absolute_error: 105.3687\n","Epoch 116/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.8229 - mean_absolute_error: 0.8229 - val_loss: 101.5912 - val_mean_absolute_error: 101.5912\n","Epoch 117/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7779 - mean_absolute_error: 0.7779 - val_loss: 97.1075 - val_mean_absolute_error: 97.1075\n","Epoch 118/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7796 - mean_absolute_error: 0.7796 - val_loss: 78.9947 - val_mean_absolute_error: 78.9947\n","Epoch 119/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7921 - mean_absolute_error: 0.7921 - val_loss: 83.3280 - val_mean_absolute_error: 83.3280\n","Epoch 120/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7877 - mean_absolute_error: 0.7877 - val_loss: 86.6187 - val_mean_absolute_error: 86.6187\n","Epoch 121/200\n","729000/729000 [==============================] - 128s 175us/step - loss: 0.8420 - mean_absolute_error: 0.8420 - val_loss: 76.7023 - val_mean_absolute_error: 76.7023\n","Epoch 122/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7748 - mean_absolute_error: 0.7748 - val_loss: 85.4975 - val_mean_absolute_error: 85.4975\n","Epoch 123/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7980 - mean_absolute_error: 0.7980 - val_loss: 78.8683 - val_mean_absolute_error: 78.8683\n","Epoch 124/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.8319 - mean_absolute_error: 0.8319 - val_loss: 69.0266 - val_mean_absolute_error: 69.0266\n","Epoch 125/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7292 - mean_absolute_error: 0.7292 - val_loss: 93.8231 - val_mean_absolute_error: 93.8231\n","Epoch 126/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7981 - mean_absolute_error: 0.7981 - val_loss: 103.3152 - val_mean_absolute_error: 103.3152\n","Epoch 127/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 0.7551 - mean_absolute_error: 0.7551 - val_loss: 75.4604 - val_mean_absolute_error: 75.4604\n","Epoch 128/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7414 - mean_absolute_error: 0.7414 - val_loss: 52.9707 - val_mean_absolute_error: 52.9707\n","Epoch 129/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 0.8084 - mean_absolute_error: 0.8084 - val_loss: 109.7675 - val_mean_absolute_error: 109.7675\n","Epoch 130/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7760 - mean_absolute_error: 0.7760 - val_loss: 103.8664 - val_mean_absolute_error: 103.8664\n","Epoch 131/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7856 - mean_absolute_error: 0.7856 - val_loss: 107.5991 - val_mean_absolute_error: 107.5991\n","Epoch 132/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7928 - mean_absolute_error: 0.7928 - val_loss: 85.6390 - val_mean_absolute_error: 85.6390\n","Epoch 133/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.8096 - mean_absolute_error: 0.8096 - val_loss: 104.1272 - val_mean_absolute_error: 104.1272\n","Epoch 134/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7945 - mean_absolute_error: 0.7945 - val_loss: 101.4815 - val_mean_absolute_error: 101.4815\n","Epoch 135/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7976 - mean_absolute_error: 0.7976 - val_loss: 100.3558 - val_mean_absolute_error: 100.3558\n","Epoch 136/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7535 - mean_absolute_error: 0.7535 - val_loss: 85.0442 - val_mean_absolute_error: 85.0442\n","Epoch 137/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7304 - mean_absolute_error: 0.7304 - val_loss: 89.8792 - val_mean_absolute_error: 89.8792\n","Epoch 138/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7510 - mean_absolute_error: 0.7510 - val_loss: 88.1944 - val_mean_absolute_error: 88.1944\n","Epoch 139/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7723 - mean_absolute_error: 0.7723 - val_loss: 96.1763 - val_mean_absolute_error: 96.1763\n","Epoch 140/200\n","729000/729000 [==============================] - 127s 175us/step - loss: 0.7720 - mean_absolute_error: 0.7720 - val_loss: 57.0249 - val_mean_absolute_error: 57.0249\n","Epoch 141/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7999 - mean_absolute_error: 0.7999 - val_loss: 107.9717 - val_mean_absolute_error: 107.9717\n","Epoch 142/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.8091 - mean_absolute_error: 0.8091 - val_loss: 72.1274 - val_mean_absolute_error: 72.1274\n","Epoch 143/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7622 - mean_absolute_error: 0.7622 - val_loss: 91.3084 - val_mean_absolute_error: 91.3084\n","Epoch 144/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7645 - mean_absolute_error: 0.7645 - val_loss: 114.3273 - val_mean_absolute_error: 114.3273\n","Epoch 145/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7515 - mean_absolute_error: 0.7515 - val_loss: 92.6829 - val_mean_absolute_error: 92.6829\n","Epoch 146/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7398 - mean_absolute_error: 0.7398 - val_loss: 97.6936 - val_mean_absolute_error: 97.6936\n","Epoch 147/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7945 - mean_absolute_error: 0.7945 - val_loss: 104.3110 - val_mean_absolute_error: 104.3110\n","Epoch 148/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7503 - mean_absolute_error: 0.7503 - val_loss: 82.5608 - val_mean_absolute_error: 82.5608\n","Epoch 149/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7815 - mean_absolute_error: 0.7815 - val_loss: 95.2196 - val_mean_absolute_error: 95.2196\n","Epoch 150/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7714 - mean_absolute_error: 0.7714 - val_loss: 91.7087 - val_mean_absolute_error: 91.7087\n","Epoch 151/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7399 - mean_absolute_error: 0.7399 - val_loss: 89.5434 - val_mean_absolute_error: 89.5434\n","Epoch 152/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7949 - mean_absolute_error: 0.7949 - val_loss: 107.1188 - val_mean_absolute_error: 107.1188\n","Epoch 153/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7265 - mean_absolute_error: 0.7265 - val_loss: 118.1670 - val_mean_absolute_error: 118.1670\n","Epoch 154/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7609 - mean_absolute_error: 0.7609 - val_loss: 118.1788 - val_mean_absolute_error: 118.1788\n","Epoch 155/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7410 - mean_absolute_error: 0.7410 - val_loss: 99.4076 - val_mean_absolute_error: 99.4076\n","Epoch 156/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7597 - mean_absolute_error: 0.7597 - val_loss: 95.9747 - val_mean_absolute_error: 95.9747\n","Epoch 157/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7790 - mean_absolute_error: 0.7790 - val_loss: 115.9522 - val_mean_absolute_error: 115.9522\n","Epoch 158/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7502 - mean_absolute_error: 0.7502 - val_loss: 116.7778 - val_mean_absolute_error: 116.7778\n","Epoch 159/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7523 - mean_absolute_error: 0.7523 - val_loss: 89.5922 - val_mean_absolute_error: 89.5922\n","Epoch 160/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7214 - mean_absolute_error: 0.7214 - val_loss: 102.8422 - val_mean_absolute_error: 102.8422\n","Epoch 161/200\n","729000/729000 [==============================] - 126s 174us/step - loss: 0.7267 - mean_absolute_error: 0.7267 - val_loss: 102.5325 - val_mean_absolute_error: 102.5325\n","Epoch 162/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7283 - mean_absolute_error: 0.7283 - val_loss: 117.9340 - val_mean_absolute_error: 117.9340\n","Epoch 163/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7888 - mean_absolute_error: 0.7888 - val_loss: 119.6349 - val_mean_absolute_error: 119.6349\n","Epoch 164/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7046 - mean_absolute_error: 0.7046 - val_loss: 95.2721 - val_mean_absolute_error: 95.2721\n","Epoch 165/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7428 - mean_absolute_error: 0.7428 - val_loss: 106.8695 - val_mean_absolute_error: 106.8695\n","Epoch 166/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7478 - mean_absolute_error: 0.7478 - val_loss: 171.8646 - val_mean_absolute_error: 171.8646\n","Epoch 167/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7667 - mean_absolute_error: 0.7667 - val_loss: 118.9374 - val_mean_absolute_error: 118.9374\n","Epoch 168/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7381 - mean_absolute_error: 0.7381 - val_loss: 94.4473 - val_mean_absolute_error: 94.4473\n","Epoch 169/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7902 - mean_absolute_error: 0.7902 - val_loss: 109.8716 - val_mean_absolute_error: 109.8716\n","Epoch 170/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7018 - mean_absolute_error: 0.7018 - val_loss: 82.4501 - val_mean_absolute_error: 82.4501\n","Epoch 171/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6919 - mean_absolute_error: 0.6919 - val_loss: 125.4173 - val_mean_absolute_error: 125.4173\n","Epoch 172/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7556 - mean_absolute_error: 0.7556 - val_loss: 94.7765 - val_mean_absolute_error: 94.7765\n","Epoch 173/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7032 - mean_absolute_error: 0.7032 - val_loss: 101.5379 - val_mean_absolute_error: 101.5379\n","Epoch 174/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7491 - mean_absolute_error: 0.7491 - val_loss: 95.9325 - val_mean_absolute_error: 95.9325\n","Epoch 175/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6958 - mean_absolute_error: 0.6958 - val_loss: 137.3067 - val_mean_absolute_error: 137.3067\n","Epoch 176/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6893 - mean_absolute_error: 0.6893 - val_loss: 102.3863 - val_mean_absolute_error: 102.3863\n","Epoch 177/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7364 - mean_absolute_error: 0.7364 - val_loss: 150.0003 - val_mean_absolute_error: 150.0003\n","Epoch 178/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7554 - mean_absolute_error: 0.7554 - val_loss: 81.2092 - val_mean_absolute_error: 81.2092\n","Epoch 179/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7316 - mean_absolute_error: 0.7316 - val_loss: 75.3747 - val_mean_absolute_error: 75.3747\n","Epoch 180/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7723 - mean_absolute_error: 0.7723 - val_loss: 131.2213 - val_mean_absolute_error: 131.2213\n","Epoch 181/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6718 - mean_absolute_error: 0.6718 - val_loss: 81.6718 - val_mean_absolute_error: 81.6718\n","Epoch 182/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6832 - mean_absolute_error: 0.6832 - val_loss: 113.9782 - val_mean_absolute_error: 113.9782\n","Epoch 183/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7888 - mean_absolute_error: 0.7888 - val_loss: 93.9323 - val_mean_absolute_error: 93.9323\n","Epoch 184/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7136 - mean_absolute_error: 0.7136 - val_loss: 100.4684 - val_mean_absolute_error: 100.4684\n","Epoch 185/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7581 - mean_absolute_error: 0.7581 - val_loss: 117.1175 - val_mean_absolute_error: 117.1175\n","Epoch 186/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7407 - mean_absolute_error: 0.7407 - val_loss: 166.7324 - val_mean_absolute_error: 166.7324\n","Epoch 187/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6996 - mean_absolute_error: 0.6996 - val_loss: 67.7187 - val_mean_absolute_error: 67.7187\n","Epoch 188/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7377 - mean_absolute_error: 0.7377 - val_loss: 107.4596 - val_mean_absolute_error: 107.4596\n","Epoch 189/200\n","729000/729000 [==============================] - 127s 174us/step - loss: 0.7117 - mean_absolute_error: 0.7117 - val_loss: 92.9703 - val_mean_absolute_error: 92.9703\n","Epoch 190/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7245 - mean_absolute_error: 0.7245 - val_loss: 103.3203 - val_mean_absolute_error: 103.3203\n","Epoch 191/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7043 - mean_absolute_error: 0.7043 - val_loss: 98.4258 - val_mean_absolute_error: 98.4258\n","Epoch 192/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7362 - mean_absolute_error: 0.7362 - val_loss: 106.1153 - val_mean_absolute_error: 106.1153\n","Epoch 193/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6953 - mean_absolute_error: 0.6953 - val_loss: 92.5712 - val_mean_absolute_error: 92.5712\n","Epoch 194/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7351 - mean_absolute_error: 0.7351 - val_loss: 90.3298 - val_mean_absolute_error: 90.3298\n","Epoch 195/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7205 - mean_absolute_error: 0.7205 - val_loss: 96.6365 - val_mean_absolute_error: 96.6365\n","Epoch 196/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7297 - mean_absolute_error: 0.7297 - val_loss: 107.2752 - val_mean_absolute_error: 107.2752\n","Epoch 197/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7130 - mean_absolute_error: 0.7130 - val_loss: 113.3769 - val_mean_absolute_error: 113.3769\n","Epoch 198/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7590 - mean_absolute_error: 0.7590 - val_loss: 135.0664 - val_mean_absolute_error: 135.0664\n","Epoch 199/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.6874 - mean_absolute_error: 0.6874 - val_loss: 97.3048 - val_mean_absolute_error: 97.3048\n","Epoch 200/200\n","729000/729000 [==============================] - 126s 173us/step - loss: 0.7165 - mean_absolute_error: 0.7165 - val_loss: 81.0793 - val_mean_absolute_error: 81.0793\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f084a436400>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"7bEBFW-Uk6Dx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"86b0608a-6556-427a-89b5-fd27591000b6","executionInfo":{"status":"ok","timestamp":1580487969083,"user_tz":-540,"elapsed":1312,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["train_Y.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(810000, 4)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"x7USr2xUmeIl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}