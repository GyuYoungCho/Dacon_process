{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras_process6.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPklCcRLLmIe7QGGjNhP68/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MpKGaXhsW3Hc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yl9ouvgzZ_Vg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"0b367ce8-c35a-4c3b-e128-1174d6a62e37","executionInfo":{"status":"ok","timestamp":1580542894115,"user_tz":-540,"elapsed":22695,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EEFS_G3aaAST","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import warnings\n","import numpy as np\n","warnings.filterwarnings('ignore')\n","train = pd.read_csv('/gdrive/My Drive/Data/trains.csv')\n","test = pd.read_csv('/gdrive/My Drive/Data/test.csv')\n","\n","for col in train.columns:\n","    col_type = train[col].dtypes\n","    min1 = train[col].min()\n","    max1 = train[col].max()\n","    if str(col_type)[:3] == 'int':\n","        train[col] = train[col].astype(np.int16)\n","    else:\n","        if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n","            train[col] = train[col].astype(np.float16)\n","        elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n","            train[col] = train[col].astype(np.float32)\n","        else:\n","            train[col] = train[col].astype(np.float64)\n","train = train.sample(frac=1,random_state=123).reset_index(drop=True)\n","train_X = train.iloc[:,4:]\n","train_Y = train.iloc[:,0:4]\n","test_X = test.iloc[:,1:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9GEPnZhacQn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"401bd8be-0e2a-40b1-ba8c-8451988e6f16","executionInfo":{"status":"ok","timestamp":1580542994446,"user_tz":-540,"elapsed":90157,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["import keras\n","from keras import backend as K\n","from keras.models import Sequential, Model\n","from keras.utils import get_custom_objects\n","from keras.layers import *\n","from keras import optimizers\n","from keras import activations\n","\n","\n","def res_unit(inputs, channels):\n","    x = BatchNormalization()(inputs)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, padding='same', use_bias=False)(x)\n","    added = Add()([inputs, x])\n","    return added\n","\n","def res_unit_stride(inputs, channels):\n","    x = BatchNormalization()(inputs)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('mish')(x)\n","    x = Conv1D(channels, kernel_size=3, padding='same', use_bias=False)(x)\n","    conv = Conv1D(channels, kernel_size=1, strides=2, padding='same', use_bias=False)(inputs)\n","    added = Add()([conv, x])\n","    return added\n","\n","class mish(Activation):\n","    def __init__(self, activation, **kwargs):\n","        super(mish, self).__init__(activation, **kwargs)\n","        self.__name__ = 'mish'\n","\n","def Mish(x):\n","    return x*K.tanh(K.softplus(x))\n","\n","get_custom_objects().update({'mish': mish(Mish)}) "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IrC8HUgvate3","colab_type":"code","colab":{}},"source":["seq_in = Input(shape=(226,1))\n","x = Conv1D(16, kernel_size=3, activation='relu', padding='valid')(seq_in)\n","x = MaxPooling1D(2, padding='valid')(x)\n","x =  res_unit(x, 16)\n","x =  res_unit(x, 16)\n","x =  res_unit(x, 16)\n","x =  res_unit_stride(x, 32)\n","x =  res_unit(x, 32)\n","x =  res_unit(x, 32)\n","x =  res_unit(x, 32)\n","x =  res_unit_stride(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit(x, 64)\n","x =  res_unit_stride(x, 128)\n","x =  res_unit(x, 128)\n","x =  res_unit(x, 128)\n","x =  res_unit(x, 128)\n","x =  res_unit_stride(x, 256)\n","x =  res_unit(x, 256)\n","x =  res_unit(x, 256)\n","x = BatchNormalization()(x)\n","x = Activation('mish')(x)\n","x = GlobalAveragePooling1D()(x)\n","x = Dense(226, kernel_initializer='he_normal', activation='linear')(x)\n","seq_out = Reshape((226,1))(x)\n","\n","model = Model(inputs=seq_in , outputs=seq_out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"65APLqsHejQe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"bdf6842a-d01d-4ad1-84fb-959323bad9b6","executionInfo":{"status":"ok","timestamp":1580544856390,"user_tz":-540,"elapsed":768,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["model.summary()"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            (None, 226, 1)       0                                            \n","__________________________________________________________________________________________________\n","conv1d_173 (Conv1D)             (None, 224, 16)      64          input_5[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling1d_5 (MaxPooling1D)  (None, 112, 16)      0           conv1d_173[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_157 (BatchN (None, 112, 16)      64          max_pooling1d_5[0][0]            \n","__________________________________________________________________________________________________\n","activation_157 (Activation)     (None, 112, 16)      0           batch_normalization_157[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_174 (Conv1D)             (None, 112, 16)      768         activation_157[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_158 (BatchN (None, 112, 16)      64          conv1d_174[0][0]                 \n","__________________________________________________________________________________________________\n","activation_158 (Activation)     (None, 112, 16)      0           batch_normalization_158[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_175 (Conv1D)             (None, 112, 16)      768         activation_158[0][0]             \n","__________________________________________________________________________________________________\n","add_77 (Add)                    (None, 112, 16)      0           max_pooling1d_5[0][0]            \n","                                                                 conv1d_175[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_159 (BatchN (None, 112, 16)      64          add_77[0][0]                     \n","__________________________________________________________________________________________________\n","activation_159 (Activation)     (None, 112, 16)      0           batch_normalization_159[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_176 (Conv1D)             (None, 112, 16)      768         activation_159[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_160 (BatchN (None, 112, 16)      64          conv1d_176[0][0]                 \n","__________________________________________________________________________________________________\n","activation_160 (Activation)     (None, 112, 16)      0           batch_normalization_160[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_177 (Conv1D)             (None, 112, 16)      768         activation_160[0][0]             \n","__________________________________________________________________________________________________\n","add_78 (Add)                    (None, 112, 16)      0           add_77[0][0]                     \n","                                                                 conv1d_177[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_161 (BatchN (None, 112, 16)      64          add_78[0][0]                     \n","__________________________________________________________________________________________________\n","activation_161 (Activation)     (None, 112, 16)      0           batch_normalization_161[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_178 (Conv1D)             (None, 112, 16)      768         activation_161[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_162 (BatchN (None, 112, 16)      64          conv1d_178[0][0]                 \n","__________________________________________________________________________________________________\n","activation_162 (Activation)     (None, 112, 16)      0           batch_normalization_162[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_179 (Conv1D)             (None, 112, 16)      768         activation_162[0][0]             \n","__________________________________________________________________________________________________\n","add_79 (Add)                    (None, 112, 16)      0           add_78[0][0]                     \n","                                                                 conv1d_179[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_163 (BatchN (None, 112, 16)      64          add_79[0][0]                     \n","__________________________________________________________________________________________________\n","activation_163 (Activation)     (None, 112, 16)      0           batch_normalization_163[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_180 (Conv1D)             (None, 56, 32)       1536        activation_163[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_164 (BatchN (None, 56, 32)       128         conv1d_180[0][0]                 \n","__________________________________________________________________________________________________\n","activation_164 (Activation)     (None, 56, 32)       0           batch_normalization_164[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_182 (Conv1D)             (None, 56, 32)       512         add_79[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_181 (Conv1D)             (None, 56, 32)       3072        activation_164[0][0]             \n","__________________________________________________________________________________________________\n","add_80 (Add)                    (None, 56, 32)       0           conv1d_182[0][0]                 \n","                                                                 conv1d_181[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_165 (BatchN (None, 56, 32)       128         add_80[0][0]                     \n","__________________________________________________________________________________________________\n","activation_165 (Activation)     (None, 56, 32)       0           batch_normalization_165[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_183 (Conv1D)             (None, 56, 32)       3072        activation_165[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_166 (BatchN (None, 56, 32)       128         conv1d_183[0][0]                 \n","__________________________________________________________________________________________________\n","activation_166 (Activation)     (None, 56, 32)       0           batch_normalization_166[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_184 (Conv1D)             (None, 56, 32)       3072        activation_166[0][0]             \n","__________________________________________________________________________________________________\n","add_81 (Add)                    (None, 56, 32)       0           add_80[0][0]                     \n","                                                                 conv1d_184[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_167 (BatchN (None, 56, 32)       128         add_81[0][0]                     \n","__________________________________________________________________________________________________\n","activation_167 (Activation)     (None, 56, 32)       0           batch_normalization_167[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_185 (Conv1D)             (None, 56, 32)       3072        activation_167[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_168 (BatchN (None, 56, 32)       128         conv1d_185[0][0]                 \n","__________________________________________________________________________________________________\n","activation_168 (Activation)     (None, 56, 32)       0           batch_normalization_168[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_186 (Conv1D)             (None, 56, 32)       3072        activation_168[0][0]             \n","__________________________________________________________________________________________________\n","add_82 (Add)                    (None, 56, 32)       0           add_81[0][0]                     \n","                                                                 conv1d_186[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_169 (BatchN (None, 56, 32)       128         add_82[0][0]                     \n","__________________________________________________________________________________________________\n","activation_169 (Activation)     (None, 56, 32)       0           batch_normalization_169[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_187 (Conv1D)             (None, 56, 32)       3072        activation_169[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_170 (BatchN (None, 56, 32)       128         conv1d_187[0][0]                 \n","__________________________________________________________________________________________________\n","activation_170 (Activation)     (None, 56, 32)       0           batch_normalization_170[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_188 (Conv1D)             (None, 56, 32)       3072        activation_170[0][0]             \n","__________________________________________________________________________________________________\n","add_83 (Add)                    (None, 56, 32)       0           add_82[0][0]                     \n","                                                                 conv1d_188[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_171 (BatchN (None, 56, 32)       128         add_83[0][0]                     \n","__________________________________________________________________________________________________\n","activation_171 (Activation)     (None, 56, 32)       0           batch_normalization_171[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_189 (Conv1D)             (None, 28, 64)       6144        activation_171[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_172 (BatchN (None, 28, 64)       256         conv1d_189[0][0]                 \n","__________________________________________________________________________________________________\n","activation_172 (Activation)     (None, 28, 64)       0           batch_normalization_172[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_191 (Conv1D)             (None, 28, 64)       2048        add_83[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_190 (Conv1D)             (None, 28, 64)       12288       activation_172[0][0]             \n","__________________________________________________________________________________________________\n","add_84 (Add)                    (None, 28, 64)       0           conv1d_191[0][0]                 \n","                                                                 conv1d_190[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_173 (BatchN (None, 28, 64)       256         add_84[0][0]                     \n","__________________________________________________________________________________________________\n","activation_173 (Activation)     (None, 28, 64)       0           batch_normalization_173[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_192 (Conv1D)             (None, 28, 64)       12288       activation_173[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_174 (BatchN (None, 28, 64)       256         conv1d_192[0][0]                 \n","__________________________________________________________________________________________________\n","activation_174 (Activation)     (None, 28, 64)       0           batch_normalization_174[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_193 (Conv1D)             (None, 28, 64)       12288       activation_174[0][0]             \n","__________________________________________________________________________________________________\n","add_85 (Add)                    (None, 28, 64)       0           add_84[0][0]                     \n","                                                                 conv1d_193[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_175 (BatchN (None, 28, 64)       256         add_85[0][0]                     \n","__________________________________________________________________________________________________\n","activation_175 (Activation)     (None, 28, 64)       0           batch_normalization_175[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_194 (Conv1D)             (None, 28, 64)       12288       activation_175[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_176 (BatchN (None, 28, 64)       256         conv1d_194[0][0]                 \n","__________________________________________________________________________________________________\n","activation_176 (Activation)     (None, 28, 64)       0           batch_normalization_176[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_195 (Conv1D)             (None, 28, 64)       12288       activation_176[0][0]             \n","__________________________________________________________________________________________________\n","add_86 (Add)                    (None, 28, 64)       0           add_85[0][0]                     \n","                                                                 conv1d_195[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_177 (BatchN (None, 28, 64)       256         add_86[0][0]                     \n","__________________________________________________________________________________________________\n","activation_177 (Activation)     (None, 28, 64)       0           batch_normalization_177[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_196 (Conv1D)             (None, 28, 64)       12288       activation_177[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_178 (BatchN (None, 28, 64)       256         conv1d_196[0][0]                 \n","__________________________________________________________________________________________________\n","activation_178 (Activation)     (None, 28, 64)       0           batch_normalization_178[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_197 (Conv1D)             (None, 28, 64)       12288       activation_178[0][0]             \n","__________________________________________________________________________________________________\n","add_87 (Add)                    (None, 28, 64)       0           add_86[0][0]                     \n","                                                                 conv1d_197[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_179 (BatchN (None, 28, 64)       256         add_87[0][0]                     \n","__________________________________________________________________________________________________\n","activation_179 (Activation)     (None, 28, 64)       0           batch_normalization_179[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_198 (Conv1D)             (None, 28, 64)       12288       activation_179[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_180 (BatchN (None, 28, 64)       256         conv1d_198[0][0]                 \n","__________________________________________________________________________________________________\n","activation_180 (Activation)     (None, 28, 64)       0           batch_normalization_180[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_199 (Conv1D)             (None, 28, 64)       12288       activation_180[0][0]             \n","__________________________________________________________________________________________________\n","add_88 (Add)                    (None, 28, 64)       0           add_87[0][0]                     \n","                                                                 conv1d_199[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_181 (BatchN (None, 28, 64)       256         add_88[0][0]                     \n","__________________________________________________________________________________________________\n","activation_181 (Activation)     (None, 28, 64)       0           batch_normalization_181[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_200 (Conv1D)             (None, 14, 128)      24576       activation_181[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_182 (BatchN (None, 14, 128)      512         conv1d_200[0][0]                 \n","__________________________________________________________________________________________________\n","activation_182 (Activation)     (None, 14, 128)      0           batch_normalization_182[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_202 (Conv1D)             (None, 14, 128)      8192        add_88[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_201 (Conv1D)             (None, 14, 128)      49152       activation_182[0][0]             \n","__________________________________________________________________________________________________\n","add_89 (Add)                    (None, 14, 128)      0           conv1d_202[0][0]                 \n","                                                                 conv1d_201[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_183 (BatchN (None, 14, 128)      512         add_89[0][0]                     \n","__________________________________________________________________________________________________\n","activation_183 (Activation)     (None, 14, 128)      0           batch_normalization_183[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_203 (Conv1D)             (None, 14, 128)      49152       activation_183[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_184 (BatchN (None, 14, 128)      512         conv1d_203[0][0]                 \n","__________________________________________________________________________________________________\n","activation_184 (Activation)     (None, 14, 128)      0           batch_normalization_184[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_204 (Conv1D)             (None, 14, 128)      49152       activation_184[0][0]             \n","__________________________________________________________________________________________________\n","add_90 (Add)                    (None, 14, 128)      0           add_89[0][0]                     \n","                                                                 conv1d_204[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_185 (BatchN (None, 14, 128)      512         add_90[0][0]                     \n","__________________________________________________________________________________________________\n","activation_185 (Activation)     (None, 14, 128)      0           batch_normalization_185[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_205 (Conv1D)             (None, 14, 128)      49152       activation_185[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_186 (BatchN (None, 14, 128)      512         conv1d_205[0][0]                 \n","__________________________________________________________________________________________________\n","activation_186 (Activation)     (None, 14, 128)      0           batch_normalization_186[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_206 (Conv1D)             (None, 14, 128)      49152       activation_186[0][0]             \n","__________________________________________________________________________________________________\n","add_91 (Add)                    (None, 14, 128)      0           add_90[0][0]                     \n","                                                                 conv1d_206[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_187 (BatchN (None, 14, 128)      512         add_91[0][0]                     \n","__________________________________________________________________________________________________\n","activation_187 (Activation)     (None, 14, 128)      0           batch_normalization_187[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_207 (Conv1D)             (None, 14, 128)      49152       activation_187[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_188 (BatchN (None, 14, 128)      512         conv1d_207[0][0]                 \n","__________________________________________________________________________________________________\n","activation_188 (Activation)     (None, 14, 128)      0           batch_normalization_188[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_208 (Conv1D)             (None, 14, 128)      49152       activation_188[0][0]             \n","__________________________________________________________________________________________________\n","add_92 (Add)                    (None, 14, 128)      0           add_91[0][0]                     \n","                                                                 conv1d_208[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_189 (BatchN (None, 14, 128)      512         add_92[0][0]                     \n","__________________________________________________________________________________________________\n","activation_189 (Activation)     (None, 14, 128)      0           batch_normalization_189[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_209 (Conv1D)             (None, 7, 256)       98304       activation_189[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_190 (BatchN (None, 7, 256)       1024        conv1d_209[0][0]                 \n","__________________________________________________________________________________________________\n","activation_190 (Activation)     (None, 7, 256)       0           batch_normalization_190[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_211 (Conv1D)             (None, 7, 256)       32768       add_92[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_210 (Conv1D)             (None, 7, 256)       196608      activation_190[0][0]             \n","__________________________________________________________________________________________________\n","add_93 (Add)                    (None, 7, 256)       0           conv1d_211[0][0]                 \n","                                                                 conv1d_210[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_191 (BatchN (None, 7, 256)       1024        add_93[0][0]                     \n","__________________________________________________________________________________________________\n","activation_191 (Activation)     (None, 7, 256)       0           batch_normalization_191[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_212 (Conv1D)             (None, 7, 256)       196608      activation_191[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_192 (BatchN (None, 7, 256)       1024        conv1d_212[0][0]                 \n","__________________________________________________________________________________________________\n","activation_192 (Activation)     (None, 7, 256)       0           batch_normalization_192[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_213 (Conv1D)             (None, 7, 256)       196608      activation_192[0][0]             \n","__________________________________________________________________________________________________\n","add_94 (Add)                    (None, 7, 256)       0           add_93[0][0]                     \n","                                                                 conv1d_213[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_193 (BatchN (None, 7, 256)       1024        add_94[0][0]                     \n","__________________________________________________________________________________________________\n","activation_193 (Activation)     (None, 7, 256)       0           batch_normalization_193[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_214 (Conv1D)             (None, 7, 256)       196608      activation_193[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_194 (BatchN (None, 7, 256)       1024        conv1d_214[0][0]                 \n","__________________________________________________________________________________________________\n","activation_194 (Activation)     (None, 7, 256)       0           batch_normalization_194[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_215 (Conv1D)             (None, 7, 256)       196608      activation_194[0][0]             \n","__________________________________________________________________________________________________\n","add_95 (Add)                    (None, 7, 256)       0           add_94[0][0]                     \n","                                                                 conv1d_215[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_195 (BatchN (None, 7, 256)       1024        add_95[0][0]                     \n","__________________________________________________________________________________________________\n","activation_195 (Activation)     (None, 7, 256)       0           batch_normalization_195[0][0]    \n","__________________________________________________________________________________________________\n","global_average_pooling1d_5 (Glo (None, 256)          0           activation_195[0][0]             \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 226)          58082       global_average_pooling1d_5[0][0] \n","__________________________________________________________________________________________________\n","reshape_7 (Reshape)             (None, 226, 1)       0           dense_12[0][0]                   \n","==================================================================================================\n","Total params: 1,710,306\n","Trainable params: 1,703,170\n","Non-trainable params: 7,136\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZEgrWEhkXRP","colab_type":"code","colab":{}},"source":["op = optimizers.Adam(lr = 0.001 , beta_1 = 0.9, beta_2 = 0.999)\n","model.compile(loss='mae', optimizer=op, metrics=['mae'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdYgekbgfxkb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"583c45d5-2a8b-4173-ae71-bf8618a9e50a","executionInfo":{"status":"ok","timestamp":1580544991587,"user_tz":-540,"elapsed":628,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["from keras.callbacks import Callback\n","import matplotlib.pyplot as plt\n","import keras.backend as K\n","plt.figure(figsize = (13,8))\n","class LRFinder(Callback):\n","    \n","    def __init__(self, min_lr=1e-5, max_lr=1e-2, steps_per_epoch=None, epochs=None):\n","        super().__init__()\n","        self.total_iterations = steps_per_epoch * epochs\n","        self.min_lr = min_lr\n","        self.max_lr = max_lr\n","        self.iteration = 0\n","        self.history = {}\n","        \n","    def clr(self):\n","        '''Calculate the learning rate.'''\n","        x = self.iteration / self.total_iterations \n","        return self.min_lr + (self.max_lr-self.min_lr) * x\n","        \n","    def on_train_begin(self, logs=None):\n","        '''Initialize the learning rate to the minimum value at the start of training.'''\n","        logs = logs or {}\n","        K.set_value(self.model.optimizer.lr, self.min_lr)\n","        \n","    def on_batch_end(self, epoch, logs=None):\n","        '''Record previous batch statistics and update the learning rate.'''\n","        logs = logs or {}\n","        self.iteration += 1\n","\n","        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n","        self.history.setdefault('iterations', []).append(self.iteration)\n","\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","            \n","        K.set_value(self.model.optimizer.lr, self.clr())\n","    def plot_lr(self):\n","        '''Helper function to quickly inspect the learning rate schedule.'''\n","        plt.plot(self.history['iterations'], self.history['lr'])\n","        plt.yscale('log')\n","        plt.xlabel('Iteration')\n","        plt.ylabel('Learning rate')\n","        \n","    def plot_loss(self):\n","        '''Helper function to quickly observe the learning rate experiment results.'''\n","        plt.plot(self.history['lr'], self.history['loss'])\n","        plt.xscale('log')\n","        plt.xlabel('Learning rate')\n","        plt.ylabel('Loss')"],"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 936x576 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"tNb30svKkJrb","colab_type":"code","colab":{}},"source":["epochs = 100\n","batch_size = 1000\n","epoch_size = len(train_X)\n","\n","lr_finder = LRFinder(min_lr=1e-5, \n","                     max_lr=1e-3, \n","                     steps_per_epoch=np.ceil(epoch_size/batch_size), \n","                     epochs=epochs)\n","\n","early_stop = keras.callbacks.EarlyStopping(patience=20, monitor='val_loss')\n","\n","ckpt_dir = '/gdrive/My Drive/ckpt2'\n","ckpt_path = ckpt_dir + '/encoder_{epoch:02d}_valloss{val_loss:.2f}.hdf5'\n","ckpt = keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFsZtYSHjzRT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":404},"outputId":"5bbb5c7a-55bf-4521-e06f-86581432870a","executionInfo":{"status":"error","timestamp":1580543850681,"user_tz":-540,"elapsed":5609,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["\n","train_X = np.expand_dims(train_X, axis=2)\n","model.fit(train_X, train_X, epochs=20, batch_size=1000, callbacks=[ckpt, lr_finder], validation_split=0.1,shuffle=True)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Train on 729000 samples, validate on 81000 samples\n","Epoch 1/20\n"," 21000/729000 [..............................] - ETA: 1:59 - loss: 0.0062 - mean_absolute_error: 0.0062"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-65df924b01f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_finder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 192\u001b[0;31m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[1;32m    193\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"7bEBFW-Uk6Dx","colab_type":"code","colab":{}},"source":["model.load_weights('/gdrive/My Drive/ckpt2/encoder_01_valloss0.00.hdf5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7USr2xUmeIl","colab_type":"code","colab":{}},"source":["outputs =  Dense(4, kernel_initializer='he_normal',activation='linear')(x)\n","\n","new_model = Model(inputs=seq_in, outputs=outputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpuXFHhIwHd2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b7439728-5bcb-452b-f6f0-afa117b00e2a","executionInfo":{"status":"ok","timestamp":1580548169992,"user_tz":-540,"elapsed":746,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["new_model.summary()"],"execution_count":56,"outputs":[{"output_type":"stream","text":["Model: \"model_15\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            (None, 226, 1)       0                                            \n","__________________________________________________________________________________________________\n","conv1d_216 (Conv1D)             (None, 224, 16)      64          input_6[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling1d_6 (MaxPooling1D)  (None, 112, 16)      0           conv1d_216[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_196 (BatchN (None, 112, 16)      64          max_pooling1d_6[0][0]            \n","__________________________________________________________________________________________________\n","activation_196 (Activation)     (None, 112, 16)      0           batch_normalization_196[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_217 (Conv1D)             (None, 112, 16)      768         activation_196[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_197 (BatchN (None, 112, 16)      64          conv1d_217[0][0]                 \n","__________________________________________________________________________________________________\n","activation_197 (Activation)     (None, 112, 16)      0           batch_normalization_197[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_218 (Conv1D)             (None, 112, 16)      768         activation_197[0][0]             \n","__________________________________________________________________________________________________\n","add_96 (Add)                    (None, 112, 16)      0           max_pooling1d_6[0][0]            \n","                                                                 conv1d_218[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_198 (BatchN (None, 112, 16)      64          add_96[0][0]                     \n","__________________________________________________________________________________________________\n","activation_198 (Activation)     (None, 112, 16)      0           batch_normalization_198[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_219 (Conv1D)             (None, 112, 16)      768         activation_198[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_199 (BatchN (None, 112, 16)      64          conv1d_219[0][0]                 \n","__________________________________________________________________________________________________\n","activation_199 (Activation)     (None, 112, 16)      0           batch_normalization_199[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_220 (Conv1D)             (None, 112, 16)      768         activation_199[0][0]             \n","__________________________________________________________________________________________________\n","add_97 (Add)                    (None, 112, 16)      0           add_96[0][0]                     \n","                                                                 conv1d_220[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_200 (BatchN (None, 112, 16)      64          add_97[0][0]                     \n","__________________________________________________________________________________________________\n","activation_200 (Activation)     (None, 112, 16)      0           batch_normalization_200[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_221 (Conv1D)             (None, 112, 16)      768         activation_200[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_201 (BatchN (None, 112, 16)      64          conv1d_221[0][0]                 \n","__________________________________________________________________________________________________\n","activation_201 (Activation)     (None, 112, 16)      0           batch_normalization_201[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_222 (Conv1D)             (None, 112, 16)      768         activation_201[0][0]             \n","__________________________________________________________________________________________________\n","add_98 (Add)                    (None, 112, 16)      0           add_97[0][0]                     \n","                                                                 conv1d_222[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_202 (BatchN (None, 112, 16)      64          add_98[0][0]                     \n","__________________________________________________________________________________________________\n","activation_202 (Activation)     (None, 112, 16)      0           batch_normalization_202[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_223 (Conv1D)             (None, 56, 32)       1536        activation_202[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_203 (BatchN (None, 56, 32)       128         conv1d_223[0][0]                 \n","__________________________________________________________________________________________________\n","activation_203 (Activation)     (None, 56, 32)       0           batch_normalization_203[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_225 (Conv1D)             (None, 56, 32)       512         add_98[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_224 (Conv1D)             (None, 56, 32)       3072        activation_203[0][0]             \n","__________________________________________________________________________________________________\n","add_99 (Add)                    (None, 56, 32)       0           conv1d_225[0][0]                 \n","                                                                 conv1d_224[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_204 (BatchN (None, 56, 32)       128         add_99[0][0]                     \n","__________________________________________________________________________________________________\n","activation_204 (Activation)     (None, 56, 32)       0           batch_normalization_204[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_226 (Conv1D)             (None, 56, 32)       3072        activation_204[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_205 (BatchN (None, 56, 32)       128         conv1d_226[0][0]                 \n","__________________________________________________________________________________________________\n","activation_205 (Activation)     (None, 56, 32)       0           batch_normalization_205[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_227 (Conv1D)             (None, 56, 32)       3072        activation_205[0][0]             \n","__________________________________________________________________________________________________\n","add_100 (Add)                   (None, 56, 32)       0           add_99[0][0]                     \n","                                                                 conv1d_227[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_206 (BatchN (None, 56, 32)       128         add_100[0][0]                    \n","__________________________________________________________________________________________________\n","activation_206 (Activation)     (None, 56, 32)       0           batch_normalization_206[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_228 (Conv1D)             (None, 56, 32)       3072        activation_206[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_207 (BatchN (None, 56, 32)       128         conv1d_228[0][0]                 \n","__________________________________________________________________________________________________\n","activation_207 (Activation)     (None, 56, 32)       0           batch_normalization_207[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_229 (Conv1D)             (None, 56, 32)       3072        activation_207[0][0]             \n","__________________________________________________________________________________________________\n","add_101 (Add)                   (None, 56, 32)       0           add_100[0][0]                    \n","                                                                 conv1d_229[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_208 (BatchN (None, 56, 32)       128         add_101[0][0]                    \n","__________________________________________________________________________________________________\n","activation_208 (Activation)     (None, 56, 32)       0           batch_normalization_208[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_230 (Conv1D)             (None, 56, 32)       3072        activation_208[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_209 (BatchN (None, 56, 32)       128         conv1d_230[0][0]                 \n","__________________________________________________________________________________________________\n","activation_209 (Activation)     (None, 56, 32)       0           batch_normalization_209[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_231 (Conv1D)             (None, 56, 32)       3072        activation_209[0][0]             \n","__________________________________________________________________________________________________\n","add_102 (Add)                   (None, 56, 32)       0           add_101[0][0]                    \n","                                                                 conv1d_231[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_210 (BatchN (None, 56, 32)       128         add_102[0][0]                    \n","__________________________________________________________________________________________________\n","activation_210 (Activation)     (None, 56, 32)       0           batch_normalization_210[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_232 (Conv1D)             (None, 28, 64)       6144        activation_210[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_211 (BatchN (None, 28, 64)       256         conv1d_232[0][0]                 \n","__________________________________________________________________________________________________\n","activation_211 (Activation)     (None, 28, 64)       0           batch_normalization_211[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_234 (Conv1D)             (None, 28, 64)       2048        add_102[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_233 (Conv1D)             (None, 28, 64)       12288       activation_211[0][0]             \n","__________________________________________________________________________________________________\n","add_103 (Add)                   (None, 28, 64)       0           conv1d_234[0][0]                 \n","                                                                 conv1d_233[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_212 (BatchN (None, 28, 64)       256         add_103[0][0]                    \n","__________________________________________________________________________________________________\n","activation_212 (Activation)     (None, 28, 64)       0           batch_normalization_212[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_235 (Conv1D)             (None, 28, 64)       12288       activation_212[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_213 (BatchN (None, 28, 64)       256         conv1d_235[0][0]                 \n","__________________________________________________________________________________________________\n","activation_213 (Activation)     (None, 28, 64)       0           batch_normalization_213[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_236 (Conv1D)             (None, 28, 64)       12288       activation_213[0][0]             \n","__________________________________________________________________________________________________\n","add_104 (Add)                   (None, 28, 64)       0           add_103[0][0]                    \n","                                                                 conv1d_236[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_214 (BatchN (None, 28, 64)       256         add_104[0][0]                    \n","__________________________________________________________________________________________________\n","activation_214 (Activation)     (None, 28, 64)       0           batch_normalization_214[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_237 (Conv1D)             (None, 28, 64)       12288       activation_214[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_215 (BatchN (None, 28, 64)       256         conv1d_237[0][0]                 \n","__________________________________________________________________________________________________\n","activation_215 (Activation)     (None, 28, 64)       0           batch_normalization_215[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_238 (Conv1D)             (None, 28, 64)       12288       activation_215[0][0]             \n","__________________________________________________________________________________________________\n","add_105 (Add)                   (None, 28, 64)       0           add_104[0][0]                    \n","                                                                 conv1d_238[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_216 (BatchN (None, 28, 64)       256         add_105[0][0]                    \n","__________________________________________________________________________________________________\n","activation_216 (Activation)     (None, 28, 64)       0           batch_normalization_216[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_239 (Conv1D)             (None, 28, 64)       12288       activation_216[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_217 (BatchN (None, 28, 64)       256         conv1d_239[0][0]                 \n","__________________________________________________________________________________________________\n","activation_217 (Activation)     (None, 28, 64)       0           batch_normalization_217[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_240 (Conv1D)             (None, 28, 64)       12288       activation_217[0][0]             \n","__________________________________________________________________________________________________\n","add_106 (Add)                   (None, 28, 64)       0           add_105[0][0]                    \n","                                                                 conv1d_240[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_218 (BatchN (None, 28, 64)       256         add_106[0][0]                    \n","__________________________________________________________________________________________________\n","activation_218 (Activation)     (None, 28, 64)       0           batch_normalization_218[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_241 (Conv1D)             (None, 28, 64)       12288       activation_218[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_219 (BatchN (None, 28, 64)       256         conv1d_241[0][0]                 \n","__________________________________________________________________________________________________\n","activation_219 (Activation)     (None, 28, 64)       0           batch_normalization_219[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_242 (Conv1D)             (None, 28, 64)       12288       activation_219[0][0]             \n","__________________________________________________________________________________________________\n","add_107 (Add)                   (None, 28, 64)       0           add_106[0][0]                    \n","                                                                 conv1d_242[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_220 (BatchN (None, 28, 64)       256         add_107[0][0]                    \n","__________________________________________________________________________________________________\n","activation_220 (Activation)     (None, 28, 64)       0           batch_normalization_220[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_243 (Conv1D)             (None, 14, 128)      24576       activation_220[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_221 (BatchN (None, 14, 128)      512         conv1d_243[0][0]                 \n","__________________________________________________________________________________________________\n","activation_221 (Activation)     (None, 14, 128)      0           batch_normalization_221[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_245 (Conv1D)             (None, 14, 128)      8192        add_107[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_244 (Conv1D)             (None, 14, 128)      49152       activation_221[0][0]             \n","__________________________________________________________________________________________________\n","add_108 (Add)                   (None, 14, 128)      0           conv1d_245[0][0]                 \n","                                                                 conv1d_244[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_222 (BatchN (None, 14, 128)      512         add_108[0][0]                    \n","__________________________________________________________________________________________________\n","activation_222 (Activation)     (None, 14, 128)      0           batch_normalization_222[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_246 (Conv1D)             (None, 14, 128)      49152       activation_222[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_223 (BatchN (None, 14, 128)      512         conv1d_246[0][0]                 \n","__________________________________________________________________________________________________\n","activation_223 (Activation)     (None, 14, 128)      0           batch_normalization_223[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_247 (Conv1D)             (None, 14, 128)      49152       activation_223[0][0]             \n","__________________________________________________________________________________________________\n","add_109 (Add)                   (None, 14, 128)      0           add_108[0][0]                    \n","                                                                 conv1d_247[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_224 (BatchN (None, 14, 128)      512         add_109[0][0]                    \n","__________________________________________________________________________________________________\n","activation_224 (Activation)     (None, 14, 128)      0           batch_normalization_224[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_248 (Conv1D)             (None, 14, 128)      49152       activation_224[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_225 (BatchN (None, 14, 128)      512         conv1d_248[0][0]                 \n","__________________________________________________________________________________________________\n","activation_225 (Activation)     (None, 14, 128)      0           batch_normalization_225[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_249 (Conv1D)             (None, 14, 128)      49152       activation_225[0][0]             \n","__________________________________________________________________________________________________\n","add_110 (Add)                   (None, 14, 128)      0           add_109[0][0]                    \n","                                                                 conv1d_249[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_226 (BatchN (None, 14, 128)      512         add_110[0][0]                    \n","__________________________________________________________________________________________________\n","activation_226 (Activation)     (None, 14, 128)      0           batch_normalization_226[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_250 (Conv1D)             (None, 14, 128)      49152       activation_226[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_227 (BatchN (None, 14, 128)      512         conv1d_250[0][0]                 \n","__________________________________________________________________________________________________\n","activation_227 (Activation)     (None, 14, 128)      0           batch_normalization_227[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_251 (Conv1D)             (None, 14, 128)      49152       activation_227[0][0]             \n","__________________________________________________________________________________________________\n","add_111 (Add)                   (None, 14, 128)      0           add_110[0][0]                    \n","                                                                 conv1d_251[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_228 (BatchN (None, 14, 128)      512         add_111[0][0]                    \n","__________________________________________________________________________________________________\n","activation_228 (Activation)     (None, 14, 128)      0           batch_normalization_228[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_252 (Conv1D)             (None, 7, 256)       98304       activation_228[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_229 (BatchN (None, 7, 256)       1024        conv1d_252[0][0]                 \n","__________________________________________________________________________________________________\n","activation_229 (Activation)     (None, 7, 256)       0           batch_normalization_229[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_254 (Conv1D)             (None, 7, 256)       32768       add_111[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_253 (Conv1D)             (None, 7, 256)       196608      activation_229[0][0]             \n","__________________________________________________________________________________________________\n","add_112 (Add)                   (None, 7, 256)       0           conv1d_254[0][0]                 \n","                                                                 conv1d_253[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_230 (BatchN (None, 7, 256)       1024        add_112[0][0]                    \n","__________________________________________________________________________________________________\n","activation_230 (Activation)     (None, 7, 256)       0           batch_normalization_230[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_255 (Conv1D)             (None, 7, 256)       196608      activation_230[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_231 (BatchN (None, 7, 256)       1024        conv1d_255[0][0]                 \n","__________________________________________________________________________________________________\n","activation_231 (Activation)     (None, 7, 256)       0           batch_normalization_231[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_256 (Conv1D)             (None, 7, 256)       196608      activation_231[0][0]             \n","__________________________________________________________________________________________________\n","add_113 (Add)                   (None, 7, 256)       0           add_112[0][0]                    \n","                                                                 conv1d_256[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_232 (BatchN (None, 7, 256)       1024        add_113[0][0]                    \n","__________________________________________________________________________________________________\n","activation_232 (Activation)     (None, 7, 256)       0           batch_normalization_232[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_257 (Conv1D)             (None, 7, 256)       196608      activation_232[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_233 (BatchN (None, 7, 256)       1024        conv1d_257[0][0]                 \n","__________________________________________________________________________________________________\n","activation_233 (Activation)     (None, 7, 256)       0           batch_normalization_233[0][0]    \n","__________________________________________________________________________________________________\n","conv1d_258 (Conv1D)             (None, 7, 256)       196608      activation_233[0][0]             \n","__________________________________________________________________________________________________\n","add_114 (Add)                   (None, 7, 256)       0           add_113[0][0]                    \n","                                                                 conv1d_258[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_234 (BatchN (None, 7, 256)       1024        add_114[0][0]                    \n","__________________________________________________________________________________________________\n","activation_234 (Activation)     (None, 7, 256)       0           batch_normalization_234[0][0]    \n","__________________________________________________________________________________________________\n","global_average_pooling1d_6 (Glo (None, 256)          0           activation_234[0][0]             \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 226)          58082       global_average_pooling1d_6[0][0] \n","__________________________________________________________________________________________________\n","dense_21 (Dense)                (None, 4)            908         dense_15[0][0]                   \n","==================================================================================================\n","Total params: 1,711,214\n","Trainable params: 1,704,078\n","Non-trainable params: 7,136\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X0HOIHlN1TRl","colab_type":"code","colab":{}},"source":["new_model.compile(loss='mae', optimizer=op,metrics=['mae'])\n","ckpt_path = ckpt_dir + '/modeling_{epoch:02d}_valloss{val_loss:.2f}.hdf5'\n","ckpt = keras.callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cVnSDqAQ2TAt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f1450d45-6e0f-4391-ffab-893f2199ffee","executionInfo":{"status":"ok","timestamp":1580559861172,"user_tz":-540,"elapsed":11615447,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["new_model.fit(train_X, train_Y, epochs=100, batch_size=1000, callbacks=[ckpt], validation_split=0.2,shuffle=True)"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Train on 648000 samples, validate on 162000 samples\n","Epoch 1/100\n","648000/648000 [==============================] - 129s 199us/step - loss: 23.7019 - mean_absolute_error: 23.7019 - val_loss: 36.0178 - val_mean_absolute_error: 36.0178\n","Epoch 2/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 6.3317 - mean_absolute_error: 6.3317 - val_loss: 36.8734 - val_mean_absolute_error: 36.8734\n","Epoch 3/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 4.9293 - mean_absolute_error: 4.9293 - val_loss: 5.6464 - val_mean_absolute_error: 5.6464\n","Epoch 4/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 4.5282 - mean_absolute_error: 4.5282 - val_loss: 28.3474 - val_mean_absolute_error: 28.3474\n","Epoch 5/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 4.1164 - mean_absolute_error: 4.1164 - val_loss: 10.2571 - val_mean_absolute_error: 10.2571\n","Epoch 6/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 3.8698 - mean_absolute_error: 3.8698 - val_loss: 12.0326 - val_mean_absolute_error: 12.0326\n","Epoch 7/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 3.7720 - mean_absolute_error: 3.7720 - val_loss: 5.0762 - val_mean_absolute_error: 5.0762\n","Epoch 8/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 3.6754 - mean_absolute_error: 3.6754 - val_loss: 3.6198 - val_mean_absolute_error: 3.6198\n","Epoch 9/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 3.7115 - mean_absolute_error: 3.7115 - val_loss: 6.3915 - val_mean_absolute_error: 6.3915\n","Epoch 10/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 3.4941 - mean_absolute_error: 3.4941 - val_loss: 24.9650 - val_mean_absolute_error: 24.9650\n","Epoch 11/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 3.3728 - mean_absolute_error: 3.3728 - val_loss: 24.6475 - val_mean_absolute_error: 24.6475\n","Epoch 12/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 3.3727 - mean_absolute_error: 3.3727 - val_loss: 4.7652 - val_mean_absolute_error: 4.7652\n","Epoch 13/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 3.2993 - mean_absolute_error: 3.2993 - val_loss: 3.5105 - val_mean_absolute_error: 3.5105\n","Epoch 14/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 3.1467 - mean_absolute_error: 3.1467 - val_loss: 11.0350 - val_mean_absolute_error: 11.0350\n","Epoch 15/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 3.1634 - mean_absolute_error: 3.1634 - val_loss: 4.9977 - val_mean_absolute_error: 4.9977\n","Epoch 16/100\n","648000/648000 [==============================] - 115s 178us/step - loss: 3.1893 - mean_absolute_error: 3.1893 - val_loss: 7.1505 - val_mean_absolute_error: 7.1505\n","Epoch 17/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 3.0821 - mean_absolute_error: 3.0821 - val_loss: 8.2143 - val_mean_absolute_error: 8.2143\n","Epoch 18/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 3.0254 - mean_absolute_error: 3.0254 - val_loss: 4.1167 - val_mean_absolute_error: 4.1167\n","Epoch 19/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 2.8758 - mean_absolute_error: 2.8758 - val_loss: 2.5074 - val_mean_absolute_error: 2.5074\n","Epoch 20/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.9140 - mean_absolute_error: 2.9140 - val_loss: 10.8303 - val_mean_absolute_error: 10.8303\n","Epoch 21/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 2.8806 - mean_absolute_error: 2.8806 - val_loss: 6.1599 - val_mean_absolute_error: 6.1599\n","Epoch 22/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 2.8031 - mean_absolute_error: 2.8031 - val_loss: 2.4532 - val_mean_absolute_error: 2.4532\n","Epoch 23/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 2.7758 - mean_absolute_error: 2.7758 - val_loss: 24.4291 - val_mean_absolute_error: 24.4291\n","Epoch 24/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.7602 - mean_absolute_error: 2.7602 - val_loss: 26.9570 - val_mean_absolute_error: 26.9570\n","Epoch 25/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.6548 - mean_absolute_error: 2.6548 - val_loss: 4.0741 - val_mean_absolute_error: 4.0741\n","Epoch 26/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.6256 - mean_absolute_error: 2.6256 - val_loss: 4.3754 - val_mean_absolute_error: 4.3754\n","Epoch 27/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.6323 - mean_absolute_error: 2.6323 - val_loss: 8.2578 - val_mean_absolute_error: 8.2578\n","Epoch 28/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.6202 - mean_absolute_error: 2.6202 - val_loss: 31.7765 - val_mean_absolute_error: 31.7765\n","Epoch 29/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 2.6765 - mean_absolute_error: 2.6765 - val_loss: 13.8181 - val_mean_absolute_error: 13.8181\n","Epoch 30/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 2.5124 - mean_absolute_error: 2.5124 - val_loss: 7.8459 - val_mean_absolute_error: 7.8459\n","Epoch 31/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.4887 - mean_absolute_error: 2.4887 - val_loss: 32.8328 - val_mean_absolute_error: 32.8328\n","Epoch 32/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.4430 - mean_absolute_error: 2.4430 - val_loss: 16.3350 - val_mean_absolute_error: 16.3350\n","Epoch 33/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.3617 - mean_absolute_error: 2.3617 - val_loss: 7.2817 - val_mean_absolute_error: 7.2817\n","Epoch 34/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 2.3110 - mean_absolute_error: 2.3110 - val_loss: 3.4387 - val_mean_absolute_error: 3.4387\n","Epoch 35/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.2145 - mean_absolute_error: 2.2145 - val_loss: 2.4599 - val_mean_absolute_error: 2.4599\n","Epoch 36/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.2048 - mean_absolute_error: 2.2048 - val_loss: 11.8401 - val_mean_absolute_error: 11.8401\n","Epoch 37/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.1730 - mean_absolute_error: 2.1730 - val_loss: 2.3177 - val_mean_absolute_error: 2.3177\n","Epoch 38/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 2.0616 - mean_absolute_error: 2.0616 - val_loss: 6.3677 - val_mean_absolute_error: 6.3677\n","Epoch 39/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.9826 - mean_absolute_error: 1.9826 - val_loss: 5.0940 - val_mean_absolute_error: 5.0940\n","Epoch 40/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.9349 - mean_absolute_error: 1.9349 - val_loss: 16.0905 - val_mean_absolute_error: 16.0905\n","Epoch 41/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.8800 - mean_absolute_error: 1.8800 - val_loss: 3.7179 - val_mean_absolute_error: 3.7179\n","Epoch 42/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.8033 - mean_absolute_error: 1.8033 - val_loss: 3.5920 - val_mean_absolute_error: 3.5920\n","Epoch 43/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.7791 - mean_absolute_error: 1.7791 - val_loss: 26.6799 - val_mean_absolute_error: 26.6799\n","Epoch 44/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.7007 - mean_absolute_error: 1.7007 - val_loss: 6.0631 - val_mean_absolute_error: 6.0631\n","Epoch 45/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.6810 - mean_absolute_error: 1.6810 - val_loss: 23.6777 - val_mean_absolute_error: 23.6777\n","Epoch 46/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.5940 - mean_absolute_error: 1.5940 - val_loss: 5.6790 - val_mean_absolute_error: 5.6790\n","Epoch 47/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.5692 - mean_absolute_error: 1.5692 - val_loss: 2.1675 - val_mean_absolute_error: 2.1675\n","Epoch 48/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.4800 - mean_absolute_error: 1.4800 - val_loss: 7.6201 - val_mean_absolute_error: 7.6201\n","Epoch 49/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.4870 - mean_absolute_error: 1.4870 - val_loss: 3.1479 - val_mean_absolute_error: 3.1479\n","Epoch 50/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.5052 - mean_absolute_error: 1.5052 - val_loss: 26.2872 - val_mean_absolute_error: 26.2872\n","Epoch 51/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 1.4350 - mean_absolute_error: 1.4350 - val_loss: 16.4267 - val_mean_absolute_error: 16.4267\n","Epoch 52/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.3645 - mean_absolute_error: 1.3645 - val_loss: 3.6962 - val_mean_absolute_error: 3.6962\n","Epoch 53/100\n","648000/648000 [==============================] - 115s 178us/step - loss: 1.3688 - mean_absolute_error: 1.3688 - val_loss: 35.3733 - val_mean_absolute_error: 35.3733\n","Epoch 54/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 1.3042 - mean_absolute_error: 1.3042 - val_loss: 6.9553 - val_mean_absolute_error: 6.9553\n","Epoch 55/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.2814 - mean_absolute_error: 1.2814 - val_loss: 1.5528 - val_mean_absolute_error: 1.5528\n","Epoch 56/100\n","648000/648000 [==============================] - 116s 178us/step - loss: 1.2523 - mean_absolute_error: 1.2523 - val_loss: 3.4873 - val_mean_absolute_error: 3.4873\n","Epoch 57/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.2239 - mean_absolute_error: 1.2239 - val_loss: 3.8004 - val_mean_absolute_error: 3.8004\n","Epoch 58/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.2055 - mean_absolute_error: 1.2055 - val_loss: 6.1767 - val_mean_absolute_error: 6.1767\n","Epoch 59/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.1790 - mean_absolute_error: 1.1790 - val_loss: 7.9472 - val_mean_absolute_error: 7.9472\n","Epoch 60/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.1608 - mean_absolute_error: 1.1608 - val_loss: 1.6735 - val_mean_absolute_error: 1.6735\n","Epoch 61/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.1509 - mean_absolute_error: 1.1509 - val_loss: 4.2983 - val_mean_absolute_error: 4.2983\n","Epoch 62/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0579 - mean_absolute_error: 1.0579 - val_loss: 3.7169 - val_mean_absolute_error: 3.7169\n","Epoch 63/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0959 - mean_absolute_error: 1.0959 - val_loss: 5.8038 - val_mean_absolute_error: 5.8038\n","Epoch 64/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0950 - mean_absolute_error: 1.0950 - val_loss: 3.7901 - val_mean_absolute_error: 3.7901\n","Epoch 65/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0715 - mean_absolute_error: 1.0715 - val_loss: 7.2260 - val_mean_absolute_error: 7.2260\n","Epoch 66/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0080 - mean_absolute_error: 1.0080 - val_loss: 2.3367 - val_mean_absolute_error: 2.3367\n","Epoch 67/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9993 - mean_absolute_error: 0.9993 - val_loss: 1.7087 - val_mean_absolute_error: 1.7087\n","Epoch 68/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0187 - mean_absolute_error: 1.0187 - val_loss: 14.4738 - val_mean_absolute_error: 14.4738\n","Epoch 69/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0153 - mean_absolute_error: 1.0153 - val_loss: 9.6845 - val_mean_absolute_error: 9.6845\n","Epoch 70/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0133 - mean_absolute_error: 1.0133 - val_loss: 2.3152 - val_mean_absolute_error: 2.3152\n","Epoch 71/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9602 - mean_absolute_error: 0.9602 - val_loss: 3.5851 - val_mean_absolute_error: 3.5851\n","Epoch 72/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9885 - mean_absolute_error: 0.9885 - val_loss: 4.5149 - val_mean_absolute_error: 4.5149\n","Epoch 73/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 1.0026 - mean_absolute_error: 1.0026 - val_loss: 3.8327 - val_mean_absolute_error: 3.8327\n","Epoch 74/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9486 - mean_absolute_error: 0.9486 - val_loss: 2.2950 - val_mean_absolute_error: 2.2950\n","Epoch 75/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9512 - mean_absolute_error: 0.9512 - val_loss: 6.1489 - val_mean_absolute_error: 6.1489\n","Epoch 76/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9328 - mean_absolute_error: 0.9328 - val_loss: 10.2537 - val_mean_absolute_error: 10.2537\n","Epoch 77/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9318 - mean_absolute_error: 0.9318 - val_loss: 8.4493 - val_mean_absolute_error: 8.4493\n","Epoch 78/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.9432 - mean_absolute_error: 0.9432 - val_loss: 1.3400 - val_mean_absolute_error: 1.3400\n","Epoch 79/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8983 - mean_absolute_error: 0.8983 - val_loss: 7.6901 - val_mean_absolute_error: 7.6901\n","Epoch 80/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8886 - mean_absolute_error: 0.8886 - val_loss: 11.9252 - val_mean_absolute_error: 11.9252\n","Epoch 81/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8967 - mean_absolute_error: 0.8967 - val_loss: 2.5222 - val_mean_absolute_error: 2.5222\n","Epoch 82/100\n","648000/648000 [==============================] - 116s 180us/step - loss: 0.8777 - mean_absolute_error: 0.8777 - val_loss: 2.4694 - val_mean_absolute_error: 2.4694\n","Epoch 83/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8873 - mean_absolute_error: 0.8873 - val_loss: 5.1690 - val_mean_absolute_error: 5.1690\n","Epoch 84/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8766 - mean_absolute_error: 0.8766 - val_loss: 2.0312 - val_mean_absolute_error: 2.0312\n","Epoch 85/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8452 - mean_absolute_error: 0.8452 - val_loss: 2.2523 - val_mean_absolute_error: 2.2523\n","Epoch 86/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8889 - mean_absolute_error: 0.8889 - val_loss: 6.4906 - val_mean_absolute_error: 6.4906\n","Epoch 87/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8612 - mean_absolute_error: 0.8612 - val_loss: 11.0797 - val_mean_absolute_error: 11.0797\n","Epoch 88/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8423 - mean_absolute_error: 0.8423 - val_loss: 2.1408 - val_mean_absolute_error: 2.1408\n","Epoch 89/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8655 - mean_absolute_error: 0.8655 - val_loss: 8.9666 - val_mean_absolute_error: 8.9666\n","Epoch 90/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8467 - mean_absolute_error: 0.8467 - val_loss: 2.4419 - val_mean_absolute_error: 2.4419\n","Epoch 91/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8566 - mean_absolute_error: 0.8566 - val_loss: 3.2720 - val_mean_absolute_error: 3.2720\n","Epoch 92/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8259 - mean_absolute_error: 0.8259 - val_loss: 2.1468 - val_mean_absolute_error: 2.1468\n","Epoch 93/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8116 - mean_absolute_error: 0.8116 - val_loss: 6.7826 - val_mean_absolute_error: 6.7826\n","Epoch 94/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8279 - mean_absolute_error: 0.8279 - val_loss: 1.7873 - val_mean_absolute_error: 1.7873\n","Epoch 95/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8082 - mean_absolute_error: 0.8082 - val_loss: 1.2278 - val_mean_absolute_error: 1.2278\n","Epoch 96/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8246 - mean_absolute_error: 0.8246 - val_loss: 2.4129 - val_mean_absolute_error: 2.4129\n","Epoch 97/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8224 - mean_absolute_error: 0.8224 - val_loss: 18.3648 - val_mean_absolute_error: 18.3648\n","Epoch 98/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.8255 - mean_absolute_error: 0.8255 - val_loss: 2.9454 - val_mean_absolute_error: 2.9454\n","Epoch 99/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.7916 - mean_absolute_error: 0.7916 - val_loss: 6.1761 - val_mean_absolute_error: 6.1761\n","Epoch 100/100\n","648000/648000 [==============================] - 116s 179us/step - loss: 0.7600 - mean_absolute_error: 0.7600 - val_loss: 3.4949 - val_mean_absolute_error: 3.4949\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbda91660b8>"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"AnF6XjdX2aIJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":404},"outputId":"e24de017-c1d0-400b-d785-b2b8e4842b93","executionInfo":{"status":"ok","timestamp":1580562978472,"user_tz":-540,"elapsed":1175256,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["new_model.load_weights('/gdrive/My Drive/ckpt2/modeling_95_valloss1.23.hdf5')\n","new_model.fit(train_X, train_Y, epochs=10, batch_size=1000, callbacks=[ckpt,lr_finder], validation_split=0.2,shuffle=True)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Train on 648000 samples, validate on 162000 samples\n","Epoch 1/10\n","648000/648000 [==============================] - 118s 182us/step - loss: 0.5578 - mean_absolute_error: 0.5578 - val_loss: 0.4991 - val_mean_absolute_error: 0.4991\n","Epoch 2/10\n","648000/648000 [==============================] - 118s 182us/step - loss: 0.5135 - mean_absolute_error: 0.5135 - val_loss: 0.4744 - val_mean_absolute_error: 0.4744\n","Epoch 3/10\n","648000/648000 [==============================] - 117s 181us/step - loss: 0.5008 - mean_absolute_error: 0.5008 - val_loss: 0.4657 - val_mean_absolute_error: 0.4657\n","Epoch 4/10\n","648000/648000 [==============================] - 117s 181us/step - loss: 0.4967 - mean_absolute_error: 0.4967 - val_loss: 0.4909 - val_mean_absolute_error: 0.4909\n","Epoch 5/10\n","648000/648000 [==============================] - 117s 181us/step - loss: 0.4972 - mean_absolute_error: 0.4972 - val_loss: 0.4855 - val_mean_absolute_error: 0.4855\n","Epoch 6/10\n","648000/648000 [==============================] - 117s 181us/step - loss: 0.4912 - mean_absolute_error: 0.4912 - val_loss: 0.4595 - val_mean_absolute_error: 0.4595\n","Epoch 7/10\n","648000/648000 [==============================] - 117s 181us/step - loss: 0.4888 - mean_absolute_error: 0.4888 - val_loss: 0.4732 - val_mean_absolute_error: 0.4732\n","Epoch 8/10\n","648000/648000 [==============================] - 117s 180us/step - loss: 0.4889 - mean_absolute_error: 0.4889 - val_loss: 0.4876 - val_mean_absolute_error: 0.4876\n","Epoch 9/10\n","648000/648000 [==============================] - 117s 180us/step - loss: 0.4871 - mean_absolute_error: 0.4871 - val_loss: 0.4714 - val_mean_absolute_error: 0.4714\n","Epoch 10/10\n","648000/648000 [==============================] - 117s 180us/step - loss: 0.4856 - mean_absolute_error: 0.4856 - val_loss: 0.5180 - val_mean_absolute_error: 0.5180\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbda7587f60>"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"i16sTtLo4cod","colab_type":"code","colab":{}},"source":["new_model.load_weights('/gdrive/My Drive/ckpt2/encoder_03_valloss0.47.hdf5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqMLc0Uq5iL2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"991d91af-b834-43fa-c18f-aee49cfeb678","executionInfo":{"status":"ok","timestamp":1580563214891,"user_tz":-540,"elapsed":236400,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["from sklearn.metrics import mean_absolute_error\n","pred = new_model.predict(train_X)\n","mean_absolute_error(train_Y[\"layer_1\"], pred[:,0])"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.33067566"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"str0mPsfcjPD","colab_type":"code","colab":{}},"source":["sample = pd.read_csv('/gdrive/My Drive/sample_submission.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J09viin9pvn9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e2678c25-40cf-4d49-b0e6-41167b464a6e","executionInfo":{"status":"ok","timestamp":1580563320060,"user_tz":-540,"elapsed":791,"user":{"displayName":"Silence S","photoUrl":"","userId":"03061238987606826786"}}},"source":["mean_absolute_error(train_Y[\"layer_4\"], pred[:,3])"],"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3808355"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"CYZmAVurxvoi","colab_type":"code","colab":{}},"source":["test_X = test.iloc[:,1:]\n","test_X = np.expand_dims(test_X, axis=2)\n","y_pred = new_model.predict(test_X)\n","sample = pd.read_csv('/gdrive/My Drive/Data/sample_submission.csv')\n","sample.iloc[:,1:] = y_pred\n","sample.to_csv('/gdrive/My Drive/Data/sample8.csv',index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUhWndGQ6v_o","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}